# LLM Parameters Configuration
# 大语言模型参数配置 - 仅包含模型调用相关内容

# LLM引擎配置
llm_engine:
  # 引擎类型
  engine_type: "zhipuai"  # zhipuai, openai, local, claude
  
  # 通用配置
  common:
    max_tokens: 1000
    temperature: 0.7
    timeout: 30.0
    retry_attempts: 3
    retry_delay: 1.0
    max_history_length: 10
    enable_caching: true
    cache_timeout: 300.0

# 智谱AI配置
zhipuai:
  model: "glm-4.5"  # glm-4, glm-3-turbo, glm-4-air
  api_key: ""  # 从环境变量 ZHIPUAI_API_KEY 读取
  api_base: "https://open.bigmodel.cn/api/paas/v4"
  
  # 请求配置
  request:
    max_tokens: 1000
    temperature: 0.7
    top_p: 0.7
  
  # 端点配置
  endpoints:
    chat: "https://open.bigmodel.cn/api/paas/v4/chat/completions"
    models: "https://open.bigmodel.cn/api/paas/v4/models"

# OpenAI配置（备用）
openai:
  model: "gpt-3.5-turbo"
  api_key: ""  # 从环境变量 OPENAI_API_KEY 读取
  api_base: ""  # 自定义API基础URL，可选
  
  # 请求配置
  request:
    max_tokens: 1000
    temperature: 0.7
    top_p: 1.0
  
  # 端点配置
  endpoints:
    chat: "https://api.openai.com/v1/chat/completions"
    models: "https://api.openai.com/v1/models"

# 本地LLM配置（备用）
local:
  model_path: ""  # 本地模型路径
  device: "auto"  # auto, cpu, cuda
  
  # 请求配置
  request:
    max_tokens: 1000
    temperature: 0.7

# Claude配置（备用）
claude:
  model: "claude-3-haiku-20240307"
  api_key: ""  # 从环境变量 ANTHROPIC_API_KEY 读取
  api_base: ""  # 自定义API基础URL，可选
  
  # 请求配置
  request:
    max_tokens: 1000
    temperature: 0.7
  
  # 端点配置
  endpoints:
    messages: "https://api.anthropic.com/v1/messages"

# 缓存配置
cache:
  enable: true
  timeout: 300.0
  max_size: 1000

# 日志配置
logging:
  enable: true
  level: "info"
  file_path: "logs/llm_interface.log"

# 错误处理配置
error_handling:
  max_retry_attempts: 3
  retry_delay: 1.0
  enable_fallback: true
