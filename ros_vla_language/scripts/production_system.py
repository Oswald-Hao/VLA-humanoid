#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ­£å¼ä½¿ç”¨ç‰ˆè¯­éŸ³è¯†åˆ«+LLM+TTSç³»ç»Ÿ
Production Speech Recognition + LLM + TTS System

å®æ—¶è¯­éŸ³å½•åˆ¶ -> LLMåˆ†æ -> JSONç”Ÿæˆ -> TTSåé¦ˆ
æ”¯æŒROSè¯é¢˜å‘å¸ƒã€å¼€æœºè‡ªå¯åŠ¨ã€æŒç»­å¯¹è¯ã€å†…å­˜TTSæµå¼æ’­æ”¾
"""

import os
import sys
import time
import asyncio
import logging
import json
import numpy as np
import threading
import io
import wave
import subprocess
import tempfile
import argparse
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from pathlib import Path
import queue
import signal
import select
import termios
import tty
import rospy
import std_msgs.msg
from std_msgs.msg import String, Bool
from sensor_msgs.msg import PointCloud2
from geometry_msgs.msg import Twist
from std_msgs.msg import UInt8MultiArray
from ros_vla_language.msg import VLACommand
import sounddevice as sd
import soundfile as sf
import edge_tts
import whisper

# ROSèŠ‚ç‚¹åˆå§‹åŒ–
print("ğŸš€ æ­£åœ¨åˆå§‹åŒ–ROSèŠ‚ç‚¹...")
try:
    rospy.init_node('vla_language_system', anonymous=True)
    print("âœ… ROSèŠ‚ç‚¹åˆå§‹åŒ–æˆåŠŸ")
except Exception as e:
    print(f"âŒ ROSèŠ‚ç‚¹åˆå§‹åŒ–å¤±è´¥: {e}")
    sys.exit(1)

# é…ç½®æ—¥å¿—
print("ğŸ“ æ­£åœ¨é…ç½®æ—¥å¿—...")
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)
print("âœ… æ—¥å¿—é…ç½®å®Œæˆ")

# ROSè¯é¢˜å‘å¸ƒå™¨
class ROSPublisher:
    """ROSè¯é¢˜å‘å¸ƒå™¨"""
    
    def __init__(self):
        # è¯­éŸ³è¯†åˆ«ç»“æœå‘å¸ƒå™¨
        self.recognition_pub = rospy.Publisher('/vla/recognition_result', String, queue_size=10)
        
        # VLAæŒ‡ä»¤å‘å¸ƒå™¨
        self.command_pub = rospy.Publisher('/vla_control/command', VLACommand, queue_size=10)
        
        logger.info("âœ… ROSè¯é¢˜å‘å¸ƒå™¨åˆå§‹åŒ–å®Œæˆï¼ˆä½¿ç”¨VLACommandæ¶ˆæ¯ç±»å‹ï¼‰")
        
    def publish_recognition(self, text: str, confidence: float):
        """å‘å¸ƒè¯­éŸ³è¯†åˆ«ç»“æœ"""
        msg = String()
        # ç¡®ä¿JSONä½¿ç”¨ensure_ascii=Falseæ¥æ­£ç¡®æ˜¾ç¤ºä¸­æ–‡
        msg.data = json.dumps({
            'text': text,
            'confidence': confidence,
            'timestamp': time.time()
        }, ensure_ascii=False)
        self.recognition_pub.publish(msg)
        logger.info(f"ğŸ“¢ å‘å¸ƒè¯­éŸ³è¯†åˆ«ç»“æœ: {text}")
    
    def publish_command(self, intent: str, confidence: float, action: Dict):
        """å‘å¸ƒVLAæŒ‡ä»¤"""
        # åˆ›å»ºVLACommandæ¶ˆæ¯
        msg = VLACommand()
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºæŒ‡ä»¤ç±»å‹ï¼ˆéœ€è¦æ‰§è¡Œæœºå™¨äººåŠ¨ä½œï¼‰
        # ä¿®å¤ï¼šä½¿ç”¨action['type']å­—æ®µæ¥åˆ¤æ–­æ˜¯å¦ä¸ºå‘½ä»¤ç±»å‹
        action_type = action.get('type', 'response')
        response_type = action.get('response_type', 'command' if action_type in ['wave', 'welcome'] else 'conversation')
        
        # ä½¿ç”¨action_typeæ¥åˆ¤æ–­æ˜¯å¦ä¸ºå‘½ä»¤ç±»å‹
        if action_type in ['wave', 'welcome'] and intent in ['wave', 'welcome', 'stop']:
            # æ˜ å°„intentåˆ°instruction
            instruction_mapping = {
                'wave': 'wave',
                'welcome': 'welcome', 
                'stop': 'none',
                'unknown': 'none'
            }
            
            instruction = instruction_mapping.get(intent, 'none')
            
            # è®¾ç½®æ¶ˆæ¯å­—æ®µ
            msg.instruction = instruction
            
            # å‘å¸ƒæ¶ˆæ¯
            self.command_pub.publish(msg)
            print(f"ğŸ¤– å‘å¸ƒæœºå™¨äººæŒ‡ä»¤: {intent} -> {instruction}")
        else:
            # å¯¹è¯ç±»å‹ï¼Œä¸å‘å¸ƒæŒ‡ä»¤
            logger.debug(f"å¯¹è¯æ¨¡å¼ï¼Œä¸å‘å¸ƒæœºå™¨äººæŒ‡ä»¤: {intent}")
            # ä»ç„¶åˆ›å»ºæ¶ˆæ¯ä½†ä¸å‘å¸ƒï¼ˆä¿æŒæ¥å£ä¸€è‡´æ€§ï¼‰
            msg.instruction = 'none'

# å†…å­˜TTSæ’­æ”¾å™¨
class MemoryTTSPlayer:
    """å†…å­˜TTSæ’­æ”¾å™¨ - æµå¼æ’­æ”¾éŸ³é¢‘åœ¨å†…å­˜ä¸­ç”Ÿæˆå’Œæ’­æ”¾"""
    
    def __init__(self, publisher: ROSPublisher, tts_config: Dict[str, Any] = None):
        self.publisher = publisher
        self.is_playing = False
        self.tts_config = tts_config or {}
        self.output_device = self.tts_config.get('output_device', 'hw:1,0')  # å¿…é¡»ä½¿ç”¨USBéŸ³é¢‘è®¾å¤‡
        self.voice = self.tts_config.get('voice', 'zh-CN-XiaoxiaoNeural')
        self.rate = self.tts_config.get('rate', '+0%')
        self.volume = self.tts_config.get('volume', '+0%')
        
        # å¤šçº¿ç¨‹å’Œä¸­æ–­æ§åˆ¶
        self.playback_process = None
        self.interrupt_flag = False
        self.interrupt_lock = threading.Lock()
        self.asr_thread = None
        self.asr_active = False
        
        # è®°å½•è®¾å¤‡ä¿¡æ¯
        device_info = f"é»˜è®¤è®¾å¤‡" if self.output_device == 'default' else f"è®¾å¤‡ {self.output_device}"
        logger.info(f"âœ… å†…å­˜TTSæ’­æ”¾å™¨åˆå§‹åŒ–å®Œæˆï¼Œè¾“å‡ºè®¾å¤‡: {device_info}")
    
    async def generate_and_play_streaming(self, text: str, voice: str = None):
        """å¼‚æ­¥ç‰ˆæœ¬çš„æµå¼ç”Ÿæˆå’Œæ’­æ”¾TTSéŸ³é¢‘ï¼ˆæ€§èƒ½ä¼˜åŒ–ç‰ˆï¼‰"""
        # ç§»é™¤æ–‡æœ¬é•¿åº¦é™åˆ¶ï¼Œè¿™å¯èƒ½å¯¼è‡´æ€§èƒ½é—®é¢˜
        # logger.info(f"ğŸµ TTSå¤„ç†æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
        
        # åœ¨æ–‡æœ¬å¼€å¤´æ·»åŠ ä¸€ä¸ªçŸ­åœé¡¿ï¼Œé˜²æ­¢ç¬¬ä¸€ä¸ªå­—è¢«åæ‰
        padded_text = "." + text if text else text
        logger.info(f"ğŸµ å¼€å§‹æµå¼ç”ŸæˆTTSéŸ³é¢‘: '{padded_text[:30]}...'")
        
        # ä½¿ç”¨é…ç½®çš„è¯­éŸ³æˆ–ä¼ å…¥çš„è¯­éŸ³
        tts_voice = voice or self.voice
        
        # è®°å½•ç”Ÿæˆå¼€å§‹æ—¶é—´
        generation_start_time = time.time()
        
        # åˆ›å»ºEdge TTSé€šä¿¡å¯¹è±¡ - å¹³è¡¡è´¨é‡å’Œæ€§èƒ½
        communicate = edge_tts.Communicate(
            text=padded_text,
            voice=tts_voice,
            rate=self.rate,  # ä½¿ç”¨é…ç½®çš„æ­£å¸¸è¯­é€Ÿ
            volume=self.volume  # ä½¿ç”¨é…ç½®çš„æ­£å¸¸éŸ³é‡
        )
        
        # çœŸæ­£çš„æµå¼TTS - è¾¹ç”Ÿæˆè¾¹æ’­æ”¾
        first_chunk_time = None
        total_chunks = 0
        total_audio_size = 0
        
        # åˆ›å»ºéŸ³é¢‘æ’­æ”¾é˜Ÿåˆ—
        import asyncio
        audio_queue = asyncio.Queue()
        playback_task = None
        
        async def audio_player():
            """éŸ³é¢‘æ’­æ”¾å™¨ä»»åŠ¡"""
            try:
                while True:
                    chunk = await audio_queue.get()
                    if chunk is None:  # ç»“æŸä¿¡å·
                        break
                    # æ’­æ”¾è¿™ä¸ªéŸ³é¢‘å—
                    await self._play_audio_chunk_async(chunk)
                    audio_queue.task_done()
            except Exception as e:
                logger.error(f"éŸ³é¢‘æ’­æ”¾å¤±è´¥: {e}")
        
        # å¯åŠ¨æ’­æ”¾ä»»åŠ¡
        playback_task = asyncio.create_task(audio_player())
        
        try:
            # æµå¼æ¥æ”¶å¹¶ç«‹å³æ’­æ”¾éŸ³é¢‘æ•°æ®
            async for chunk in communicate.stream():
                if chunk["type"] == "audio":
                    # è®°å½•ç¬¬ä¸€ä¸ªchunkçš„æ—¶é—´
                    if first_chunk_time is None:
                        first_chunk_time = time.time() - generation_start_time
                        print(f"ğŸµ [æµå¼TTS] é¦–ä¸ªéŸ³é¢‘å—ç”Ÿæˆè€—æ—¶: {first_chunk_time:.3f}ç§’")
                    
                    # ç«‹å³å‘é€åˆ°æ’­æ”¾é˜Ÿåˆ—
                    await audio_queue.put(chunk["data"])
                    total_chunks += 1
                    total_audio_size += len(chunk["data"])
                    
                    print(f"ğŸµ [æµå¼TTS] å·²æ’­æ”¾ {total_chunks} ä¸ªéŸ³é¢‘å—")
            
            # å‘é€ç»“æŸä¿¡å·
            await audio_queue.put(None)
            
            # ç­‰å¾…æ’­æ”¾å®Œæˆ
            if playback_task:
                await playback_task
                
            generation_time = time.time() - generation_start_time
            print(f"ğŸµ [æµå¼TTS] å®Œæˆ - æ€»è€—æ—¶: {generation_time:.3f}ç§’, éŸ³é¢‘å¤§å°: {total_audio_size} å­—èŠ‚, åˆ†å—æ•°: {total_chunks}")
            
            if first_chunk_time:
                print(f"ğŸµ [æµå¼TTS] ç”¨æˆ·ç­‰å¾…æ—¶é—´: {first_chunk_time:.3f}ç§’ (è€Œä¸æ˜¯{generation_time:.3f}ç§’)")
            
            return generation_time
            
        except Exception as e:
            logger.error(f"æµå¼TTSå¤±è´¥: {e}")
            # ç¡®ä¿æ’­æ”¾ä»»åŠ¡è¢«å–æ¶ˆ
            if playback_task:
                playback_task.cancel()
            return generation_time
    
    async def _play_audio_chunk_async(self, audio_chunk):
        """å¼‚æ­¥æ’­æ”¾å•ä¸ªéŸ³é¢‘å—"""
        # ä½¿ç”¨çº¿ç¨‹æ± æ¥åŒæ­¥æ’­æ”¾éŸ³é¢‘å—ï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯
        import io
        import tempfile
        
        try:
            # å°†éŸ³é¢‘å—å†™å…¥ä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                temp_file.write(audio_chunk)
                temp_file_path = temp_file.name
            
            # ä½¿ç”¨ffplayæ’­æ”¾è¿™ä¸ªéŸ³é¢‘å—
            subprocess.run([
                'ffplay', 
                '-nodisp',          # ä¸æ˜¾ç¤ºè§†é¢‘çª—å£
                '-autoexit',         # æ’­æ”¾å®Œæˆåè‡ªåŠ¨é€€å‡º
                '-loglevel', 'quiet',  # é™éŸ³æ¨¡å¼
                temp_file_path
            ], check=True, capture_output=True)
            
            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            os.unlink(temp_file_path)
            
        except Exception as e:
            logger.error(f"éŸ³é¢‘å—æ’­æ”¾å¤±è´¥: {e}")
    
    async def _play_audio_data_async(self, audio_data):
        """å¼‚æ­¥æ’­æ”¾éŸ³é¢‘æ•°æ®"""
        # ä½¿ç”¨çº¿ç¨‹æ± æ¥åŒæ­¥æ’­æ”¾ï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(None, self._play_audio_data_sync, audio_data)
    
    def generate_and_play_streaming_sync(self, text: str, voice: str = None):
        """åŒæ­¥ç‰ˆæœ¬çš„æµå¼ç”Ÿæˆå’Œæ’­æ”¾TTSéŸ³é¢‘ - æ”¯æŒä¸­æ–­ï¼ˆæè‡´æ€§èƒ½ç‰ˆï¼‰"""
        import threading
        import sys
        import select
        
        # ç§»é™¤æ–‡æœ¬é•¿åº¦é™åˆ¶ï¼Œé¿å…æ€§èƒ½é—®é¢˜
        # print(f"ğŸµ [TTSè°ƒè¯•] å¤„ç†æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
        
        def run_async_in_thread():
            """åœ¨çº¿ç¨‹ä¸­è¿è¡Œå¼‚æ­¥å‡½æ•°"""
            import asyncio
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                return loop.run_until_complete(self._generate_audio_data(text, voice))
            finally:
                loop.close()
        
        # è®°å½•æ€»å¼€å§‹æ—¶é—´
        total_start_time = time.time()
        
        # åœ¨çº¿ç¨‹ä¸­ç”ŸæˆéŸ³é¢‘æ•°æ®
        audio_data = run_async_in_thread()
        
        if not audio_data:
            logger.warning("âš ï¸ TTSç”Ÿæˆå¤±è´¥ï¼Œæ²¡æœ‰éŸ³é¢‘æ•°æ®")
            return None
        
        # è®¡ç®—ç”Ÿæˆæ—¶é—´
        generation_time = time.time() - total_start_time
        print(f"ğŸµ TTSç”Ÿæˆè€—æ—¶: {generation_time:.3f}ç§’")
        
        # åœ¨å•ç‹¬çº¿ç¨‹ä¸­æ’­æ”¾éŸ³é¢‘ï¼Œæ”¯æŒé”®ç›˜ä¸­æ–­
        def play_with_keyboard_interrupt():
            try:
                self._play_audio_data_sync(audio_data)
            except KeyboardInterrupt:
                print("\nğŸ›‘ é”®ç›˜ä¸­æ–­æ£€æµ‹åˆ°ï¼Œåœæ­¢æ’­æ”¾")
                self.interrupt_playback()
        
        play_thread = threading.Thread(target=play_with_keyboard_interrupt)
        play_thread.daemon = True
        play_thread.start()
        
        print("ğŸ’¡ TTSæ’­æ”¾ä¸­ï¼ŒæŒ‰ Ctrl+C æˆ–ç©ºæ ¼é”®å¯ä»¥ä¸­æ–­æ’­æ”¾...")
        
        # ç­‰å¾…æ’­æ”¾å®Œæˆæˆ–ç”¨æˆ·ä¸­æ–­
        while play_thread.is_alive():
            # æ£€æŸ¥é”®ç›˜è¾“å…¥
            if select.select([sys.stdin], [], [], 0.1)[0]:
                key = sys.stdin.read(1)
                if key == ' ':  # ç©ºæ ¼é”®ä¸­æ–­
                    print("\nğŸ›‘ ç©ºæ ¼é”®ä¸­æ–­æ£€æµ‹åˆ°ï¼Œåœæ­¢æ’­æ”¾")
                    self.interrupt_playback()
                    break
                elif key == '\x03':  # Ctrl+C
                    print("\nğŸ›‘ Ctrl+Cä¸­æ–­æ£€æµ‹åˆ°ï¼Œåœæ­¢æ’­æ”¾")
                    self.interrupt_playback()
                    break
            
            play_thread.join(timeout=0.1)
        
        play_thread.join(timeout=1.0)
        
        # è¿”å›ç”Ÿæˆæ—¶é—´ï¼ˆä¸åŒ…æ‹¬æ’­æ”¾æ—¶é—´ï¼‰
        return generation_time
    
    async def _generate_audio_data(self, text: str, voice: str = None):
        """å¼‚æ­¥ç”ŸæˆéŸ³é¢‘æ•°æ®ï¼ˆæè‡´æ€§èƒ½ç‰ˆï¼‰"""
        # åœ¨æ–‡æœ¬å¼€å¤´æ·»åŠ ä¸€ä¸ªçŸ­åœé¡¿ï¼Œé˜²æ­¢ç¬¬ä¸€ä¸ªå­—è¢«åæ‰
        padded_text = "." + text if text else text
        logger.info(f"ğŸµ å¼€å§‹ç”ŸæˆTTSéŸ³é¢‘: '{padded_text[:30]}...'")
        
        # ä½¿ç”¨é…ç½®çš„è¯­éŸ³æˆ–ä¼ å…¥çš„è¯­éŸ³
        tts_voice = voice or self.voice
        
        # åˆ›å»ºEdge TTSé€šä¿¡å¯¹è±¡ - å¹³è¡¡è´¨é‡å’Œæ€§èƒ½
        communicate = edge_tts.Communicate(
            text=padded_text,
            voice=tts_voice,
            rate=self.rate,  # ä½¿ç”¨é…ç½®çš„æ­£å¸¸è¯­é€Ÿ
            volume=self.volume  # ä½¿ç”¨é…ç½®çš„æ­£å¸¸éŸ³é‡
        )
        
        # æ”¶é›†æ‰€æœ‰éŸ³é¢‘æ•°æ®
        audio_data = bytearray()
        chunk_count = 0
        
        # æµå¼æ¥æ”¶éŸ³é¢‘æ•°æ®
        async for chunk in communicate.stream():
            if chunk["type"] == "audio":
                audio_data.extend(chunk["data"])
                chunk_count += 1
        
        logger.info(f"ğŸµ TTSéŸ³é¢‘ç”Ÿæˆå®Œæˆï¼Œå¤§å°: {len(audio_data)} å­—èŠ‚ï¼Œåˆ†å—: {chunk_count}")
        return audio_data
    
    def _play_audio_data_sync(self, audio_data):
        """åŒæ­¥æ’­æ”¾éŸ³é¢‘æ•°æ®ï¼ˆæ”¯æŒä¸­æ–­ï¼‰"""
        try:
            # ç›´æ¥ä½¿ç”¨ffplayé€šè¿‡ç®¡é“æ’­æ”¾ï¼Œä¸åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            # è®¾ç½®ç¯å¢ƒå˜é‡æŒ‡å®šéŸ³é¢‘è®¾å¤‡ï¼Œå°è¯•ä½¿ç”¨PulseAudioé¿å…å†²çª
            env = os.environ.copy()
            
            # ä¼˜å…ˆå°è¯•PulseAudioï¼Œå¦‚æœæ²¡æœ‰åˆ™å›é€€åˆ°ALSA
            if 'PULSE_SERVER' in os.environ:
                env['SDL_AUDIODRIVER'] = 'pulse'
                print("ğŸ”Š ä½¿ç”¨PulseAudioéŸ³é¢‘é©±åŠ¨")
            else:
                env['SDL_AUDIODRIVER'] = 'alsa'
                print("ğŸ”Š ä½¿ç”¨ALSAéŸ³é¢‘é©±åŠ¨")
            
            # ä½¿ç”¨é…ç½®çš„è¾“å‡ºè®¾å¤‡
            if self.output_device != 'default':
                if env['SDL_AUDIODRIVER'] == 'alsa':
                    env['AUDIODEV'] = self.output_device
                logger.info(f"ä½¿ç”¨æŒ‡å®šçš„è¾“å‡ºè®¾å¤‡: {self.output_device}")
            else:
                logger.info("ä½¿ç”¨é»˜è®¤è¾“å‡ºè®¾å¤‡")
            
            # ä½¿ç”¨å­è¿›ç¨‹å’Œç®¡é“æ’­æ”¾éŸ³é¢‘ï¼Œå¸¦é‡è¯•æœºåˆ¶
            max_retries = 3
            retry_delay = 0.5
            
            for attempt in range(max_retries):
                try:
                    print(f"ğŸ”Š æ­£åœ¨ä½¿ç”¨è®¾å¤‡ {self.output_device} æ’­æ”¾éŸ³é¢‘ (å°è¯• {attempt + 1}/{max_retries})...")
                    self.is_playing = True
                    self.playback_process = subprocess.Popen(
                        ['ffplay', '-autoexit', '-nodisp', '-f', 'mp3', '-ar', '24000', '-ac', '1', '-i', '-'],
                        stdin=subprocess.PIPE,
                        stdout=subprocess.PIPE,
                        stderr=subprocess.PIPE,
                        env=env
                    )
                    
                    # å°†éŸ³é¢‘æ•°æ®å†™å…¥ç®¡é“
                    stdout, stderr = self.playback_process.communicate(input=audio_data)
                    
                    if self.playback_process.returncode == 0:
                        logger.info(f"âœ… TTSéŸ³é¢‘æ’­æ”¾å®Œæˆ (ä½¿ç”¨è¾“å‡ºè®¾å¤‡: {self.output_device})")
                        break
                    else:
                        error_msg = stderr.decode('utf-8')
                        if "Device or resource busy" in error_msg and attempt < max_retries - 1:
                            print(f"âš ï¸ éŸ³é¢‘è®¾å¤‡å¿™ï¼Œç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                            time.sleep(retry_delay)
                            continue
                        else:
                            logger.error(f"âŒ éŸ³é¢‘è®¾å¤‡æ’­æ”¾å¤±è´¥: {error_msg}")
                            break
                            
                except subprocess.TimeoutExpired:
                    print(f"âš ï¸ æ’­æ”¾è¶…æ—¶ï¼Œå°è¯• {attempt + 1}/{max_retries}")
                    if attempt < max_retries - 1:
                        time.sleep(retry_delay)
                    else:
                        logger.error("âŒ éŸ³é¢‘æ’­æ”¾è¶…æ—¶")
                except Exception as e:
                    print(f"âš ï¸ æ’­æ”¾å¼‚å¸¸: {str(e)}")
                    if attempt < max_retries - 1:
                        time.sleep(retry_delay)
                    else:
                        logger.error(f"âŒ éŸ³é¢‘æ’­æ”¾å¼‚å¸¸: {str(e)}")
                finally:
                    # é‡ç½®æ’­æ”¾çŠ¶æ€
                    self.is_playing = False
                    self.playback_process = None
            
        except (subprocess.CalledProcessError, FileNotFoundError, subprocess.TimeoutExpired) as e:
            logger.error(f"âŒ éŸ³é¢‘è®¾å¤‡æ’­æ”¾å¼‚å¸¸: {str(e)}")
            self.is_playing = False
            self.playback_process = None
            
        except Exception as e:
            logger.error(f"âŒ TTSæ’­æ”¾å¤±è´¥: {str(e)}")
            self.is_playing = False
            self.playback_process = None
            
            # ç›´æ¥ä½¿ç”¨ffplayé€šè¿‡ç®¡é“æ’­æ”¾ï¼Œä¸åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            try:
                # è®¾ç½®ç¯å¢ƒå˜é‡æŒ‡å®šéŸ³é¢‘è®¾å¤‡
                env = os.environ.copy()
                env['SDL_AUDIODRIVER'] = 'alsa'
                
                # ä½¿ç”¨é…ç½®çš„è¾“å‡ºè®¾å¤‡
                if self.output_device != 'default':
                    env['AUDIODEV'] = self.output_device
                    logger.info(f"ä½¿ç”¨æŒ‡å®šçš„è¾“å‡ºè®¾å¤‡: {self.output_device}")
                else:
                    logger.info("ä½¿ç”¨é»˜è®¤è¾“å‡ºè®¾å¤‡")
                
                # ä½¿ç”¨å­è¿›ç¨‹å’Œç®¡é“æ’­æ”¾éŸ³é¢‘ï¼Œå¸¦é‡è¯•æœºåˆ¶
                max_retries = 3
                retry_delay = 0.5
                
                for attempt in range(max_retries):
                    try:
                        print(f"ğŸ”Š æ­£åœ¨ä½¿ç”¨è®¾å¤‡ {self.output_device} æ’­æ”¾éŸ³é¢‘ (å°è¯• {attempt + 1}/{max_retries})...")
                        self.is_playing = True
                        self.playback_process = subprocess.Popen(
                            ['ffplay', '-autoexit', '-nodisp', '-f', 'mp3', '-ar', '24000', '-ac', '1', '-i', '-'],
                            stdin=subprocess.PIPE,
                            stdout=subprocess.PIPE,
                            stderr=subprocess.PIPE,
                            env=env
                        )
                        
                        # å°†éŸ³é¢‘æ•°æ®å†™å…¥ç®¡é“ï¼ˆç§»é™¤è¶…æ—¶è®¾ç½®ï¼‰
                        stdout, stderr = self.playback_process.communicate(input=audio_data)
                        
                        if self.playback_process.returncode == 0:
                            logger.info(f"âœ… TTSéŸ³é¢‘æ’­æ”¾å®Œæˆ (ä½¿ç”¨è¾“å‡ºè®¾å¤‡: {self.output_device})")
                            break
                        else:
                            error_msg = stderr.decode('utf-8')
                            if "Device or resource busy" in error_msg and attempt < max_retries - 1:
                                print(f"âš ï¸ éŸ³é¢‘è®¾å¤‡å¿™ï¼Œç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                                time.sleep(retry_delay)
                                continue
                            else:
                                logger.error(f"âŒ éŸ³é¢‘è®¾å¤‡æ’­æ”¾å¤±è´¥: {error_msg}")
                                break
                                
                    except subprocess.TimeoutExpired:
                        print(f"âš ï¸ æ’­æ”¾è¶…æ—¶ï¼Œå°è¯• {attempt + 1}/{max_retries}")
                        if attempt < max_retries - 1:
                            time.sleep(retry_delay)
                        else:
                            logger.error("âŒ éŸ³é¢‘æ’­æ”¾è¶…æ—¶")
                    except Exception as e:
                        print(f"âš ï¸ æ’­æ”¾å¼‚å¸¸: {str(e)}")
                        if attempt < max_retries - 1:
                            time.sleep(retry_delay)
                        else:
                            logger.error(f"âŒ éŸ³é¢‘æ’­æ”¾å¼‚å¸¸: {str(e)}")
                    finally:
                        # é‡ç½®æ’­æ”¾çŠ¶æ€
                        self.is_playing = False
                        self.playback_process = None
                    
            except (subprocess.CalledProcessError, FileNotFoundError, subprocess.TimeoutExpired) as e:
                logger.error(f"âŒ éŸ³é¢‘è®¾å¤‡æ’­æ”¾å¼‚å¸¸: {str(e)}")
                self.is_playing = False
                self.playback_process = None
                
        except Exception as e:
            logger.error(f"âŒ TTSæµå¼ç”Ÿæˆå’Œæ’­æ”¾å¤±è´¥: {str(e)}")
            self.is_playing = False
            self.playback_process = None
    
            
    def _play_audio(self, audio_data: np.ndarray):
        """æ’­æ”¾éŸ³é¢‘ï¼ˆä¿ç•™åŸæ–¹æ³•ä»¥å…¼å®¹ï¼‰"""
        return self._play_audio_directly(audio_data)
    
    def is_playing_audio(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ­£åœ¨æ’­æ”¾éŸ³é¢‘"""
        return self.is_playing
    
    def interrupt_playback(self):
        """ä¸­æ–­éŸ³é¢‘æ’­æ”¾"""
        with self.interrupt_lock:
            if self.is_playing and self.playback_process:
                print(f"ğŸ›‘ [ä¸­æ–­] ç»ˆæ­¢TTSæ’­æ”¾...")
                try:
                    self.playback_process.terminate()
                    self.playback_process.wait(timeout=0.5)
                except:
                    try:
                        self.playback_process.kill()
                    except:
                        pass
                finally:
                    self.is_playing = False
                    self.playback_process = None
                    print(f"âœ… [ä¸­æ–­] TTSæ’­æ”¾å·²ç»ˆæ­¢")
    
    def start_asr_during_tts(self, speech_recognizer, callback):
        """åœ¨TTSæ’­æ”¾æœŸé—´å¯åŠ¨ASRçº¿ç¨‹ - ä½¿ç”¨ç‹¬ç«‹éŸ³é¢‘è®¾å¤‡"""
        if self.asr_thread and self.asr_thread.is_alive():
            print("âš ï¸ ASRç›‘å¬çº¿ç¨‹å·²åœ¨è¿è¡Œ")
            return
        
        self.asr_active = True
        self.asr_thread = threading.Thread(target=self._asr_during_tts_worker_simple, args=(speech_recognizer, callback))
        self.asr_thread.daemon = True
        self.asr_thread.start()
        print("ğŸ¤ å¯åŠ¨TTSæœŸé—´çš„ASRç›‘å¬çº¿ç¨‹ï¼ˆä½¿ç”¨ç‹¬ç«‹è®¾å¤‡ï¼‰")
        logger.info("ğŸ¤ å¯åŠ¨TTSæœŸé—´çš„ASRç›‘å¬çº¿ç¨‹")
        time.sleep(0.2)
    
    def stop_asr_during_tts(self):
        """åœæ­¢TTSæœŸé—´çš„ASRç›‘å¬"""
        self.asr_active = False
        if self.asr_thread and self.asr_thread.is_alive():
            self.asr_thread.join(timeout=1.0)
        logger.info("ğŸ›‘ åœæ­¢TTSæœŸé—´çš„ASRç›‘å¬çº¿ç¨‹")
    
    def _asr_during_tts_worker_simple(self, speech_recognizer, callback):
        """ASRå·¥ä½œçº¿ç¨‹ - ç®€åŒ–ç‰ˆæœ¬ï¼Œé¿å…å¤æ‚çš„éŸ³é¢‘è®¾å¤‡å†²çª"""
        import time
        
        try:
            print("ğŸ¤ [ASRç›‘å¬] å¯åŠ¨ç®€åŒ–ç‰ˆASRç›‘å¬ï¼ˆä»…é”®ç›˜æ£€æµ‹ï¼‰")
            print("ğŸ’¡ [ASRç›‘å¬] TTSæ’­æ”¾æœŸé—´ï¼ŒæŒ‰ç©ºæ ¼é”®å¯ä»¥ä¸­æ–­æ’­æ”¾")
            
            # ç­‰å¾…TTSå¼€å§‹æ’­æ”¾
            while self.asr_active and not self.is_playing:
                time.sleep(0.1)
            
            print("ğŸ” [ASRç›‘å¬] TTSæ’­æ”¾ä¸­ï¼Œç­‰å¾…ç”¨æˆ·ä¸­æ–­...")
            
            # ç®€å•çš„é”®ç›˜æ£€æµ‹ï¼Œé¿å…éŸ³é¢‘è®¾å¤‡å†²çª
            import sys
            import select
            
            while self.asr_active and self.is_playing:
                try:
                    # æ£€æŸ¥é”®ç›˜è¾“å…¥
                    if select.select([sys.stdin], [], [], 0.1)[0]:
                        key = sys.stdin.read(1)
                        if key == ' ':  # ç©ºæ ¼é”®ä¸­æ–­
                            print("ğŸ¯ [ASRç›‘å¬] æ£€æµ‹åˆ°ç©ºæ ¼é”®ï¼Œæ¨¡æ‹Ÿå”¤é†’è¯ä¸­æ–­")
                            callback("å¤¸çˆ¶ ä¸­æ–­")
                            break
                    
                    time.sleep(0.1)
                    
                except Exception as e:
                    print(f"âŒ [ASRç›‘å¬] é”®ç›˜æ£€æµ‹å¼‚å¸¸: {e}")
                    break
                    
        except Exception as e:
            print(f"âŒ [ASRç›‘å¬] ç®€åŒ–ç›‘å¬å¼‚å¸¸: {e}")
        finally:
            print("ğŸ›‘ [ASRç›‘å¬] çº¿ç¨‹ç»“æŸ")
    
    def _asr_during_tts_worker(self, speech_recognizer, callback):
        """ASRå·¥ä½œçº¿ç¨‹ - åœ¨TTSæ’­æ”¾æœŸé—´ç›‘å¬å”¤é†’è¯ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        import sounddevice as sd
        import numpy as np
        import time
        
        # ç®€åŒ–é…ç½®
        sample_rate = 48000
        channels = 1
        chunk_duration = 1.0  # 1ç§’ chunks
        chunk_size = int(sample_rate * chunk_duration)
        
        try:
            print("ğŸ¤ [ASRç›‘å¬] å¯åŠ¨ç®€åŒ–ç‰ˆASRç›‘å¬çº¿ç¨‹")
            
            # ç›´æ¥ä½¿ç”¨é»˜è®¤è®¾å¤‡ï¼Œé¿å…è®¾å¤‡é€‰æ‹©é—®é¢˜
            with sd.InputStream(
                samplerate=sample_rate,
                channels=channels,
                dtype=np.float32,
                blocksize=chunk_size
            ) as stream:
                print("âœ… [ASRç›‘å¬] éŸ³é¢‘æµæ‰“å¼€æˆåŠŸ")
                
                # ç­‰å¾…TTSå¼€å§‹æ’­æ”¾
                while self.asr_active and not self.is_playing:
                    time.sleep(0.1)
                
                print("ğŸ” [ASRç›‘å¬] å¼€å§‹ç›‘å¬å”¤é†’è¯...")
                
                while self.asr_active and self.is_playing:
                    try:
                        # è¯»å–1ç§’éŸ³é¢‘æ•°æ®
                        audio_data, overflowed = stream.read(chunk_size)
                        
                        if overflowed:
                            print("âš ï¸ [ASRç›‘å¬] éŸ³é¢‘ç¼“å†²åŒºæº¢å‡º")
                        
                        # ç®€å•èƒ½é‡æ£€æŸ¥
                        audio_energy = np.mean(np.abs(audio_data))
                        if audio_energy > 0.001:  # ç®€å•é˜ˆå€¼
                            print(f"ğŸ” [ASRç›‘å¬] æ£€æµ‹åˆ°è¯­éŸ³ï¼Œèƒ½é‡: {audio_energy:.4f}")
                            
                            # å¿«é€Ÿè¯†åˆ«
                            result = speech_recognizer._recognize_wake_word_only(audio_data)
                            if result and result.text:
                                cleaned_text = result.text.lower().replace("ï¼Œ", ",").replace("ã€‚", ".").replace("ï¼Ÿ", "?")
                                if "å¤¸çˆ¶" in cleaned_text:
                                    print(f"ğŸ¯ [ASRç›‘å¬] æ£€æµ‹åˆ°å”¤é†’è¯: {result.text}")
                                    callback(result.text)
                                    break
                        
                        # çŸ­æš‚ä¼‘çœ ï¼Œå‡å°‘CPUå ç”¨
                        time.sleep(0.1)
                        
                    except Exception as e:
                        print(f"âŒ [ASRç›‘å¬] å¤„ç†å¼‚å¸¸: {e}")
                        break
                        
        except Exception as e:
            print(f"âŒ [ASRç›‘å¬] çº¿ç¨‹å¼‚å¸¸: {e}")
        finally:
            print("ğŸ›‘ [ASRç›‘å¬] çº¿ç¨‹ç»“æŸ")

# æ•°æ®ç±»å®šä¹‰
@dataclass
class RecognitionResult:
    """è¯­éŸ³è¯†åˆ«ç»“æœ"""
    text: str
    confidence: float
    duration: float
    engine: str = "whisper"

@dataclass
class IntentResult:
    """æ„å›¾è¯†åˆ«ç»“æœ"""
    intent: str
    confidence: float
    action: Dict[str, Any]
    processing_time: float

@dataclass
class TTSResult:
    """TTSç”Ÿæˆç»“æœ"""
    audio_data: np.ndarray
    duration: float
    text: str
    engine: str = "edge_tts"

class AudioRecorder:
    """éŸ³é¢‘å½•åˆ¶å™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.sample_rate = config.get('sample_rate', 16000)
        self.channels = config.get('channels', 1)
        self.chunk_duration = config.get('chunk_duration', 0.5)
        self.chunk_size = int(self.sample_rate * self.chunk_duration)
        self.silence_threshold = config.get('silence_threshold', 0.05)  # æé«˜é™éŸ³é˜ˆå€¼ï¼Œå‡å°‘è¯¯è§¦å‘
        self.silence_duration = config.get('silence_duration', 5.0)
        self.min_recording_duration = config.get('min_recording_duration', 1.0)
        self.input_device = config.get('input_device', None)  # ä»é…ç½®è·å–è¾“å…¥è®¾å¤‡
        
        self.is_recording = False
        self.audio_queue = queue.Queue()
        self.silence_counter = 0
        self.recording_start_time = 0
        self.last_sound_time = 0
        
        # éŸ³é¢‘ç¼“å†²åŒº
        self.audio_buffer = []
        self.silence_buffer = []
        
        # è°ƒè¯•ä¿¡æ¯
        self.debug_audio_levels = []
        self.last_debug_time = time.time()
        self.debug_interval = 2.0  # æ¯2ç§’è¾“å‡ºä¸€æ¬¡è°ƒè¯•ä¿¡æ¯
        
        # è®°å½•è®¾å¤‡ä¿¡æ¯
        device_info = f"é»˜è®¤è®¾å¤‡" if self.input_device is None else f"è®¾å¤‡ {self.input_device}"
        logger.info(f"éŸ³é¢‘å½•åˆ¶å™¨åˆå§‹åŒ–: {self.sample_rate}Hz, {self.channels}ch, è¾“å…¥è®¾å¤‡: {device_info}")
    
    def _detect_silence(self, audio_data: np.ndarray) -> bool:
        """æ£€æµ‹é™éŸ³"""
        if len(audio_data) == 0:
            return True
        
        # è®¡ç®—éŸ³é¢‘èƒ½é‡
        energy = np.mean(np.abs(audio_data))
        return energy < self.silence_threshold
    
    def _audio_callback(self, indata, frames, time_info, status):
        """éŸ³é¢‘å›è°ƒå‡½æ•°"""
        if status:
            logger.warning(f"éŸ³é¢‘å›è°ƒçŠ¶æ€: {status}")
        
        # å°†éŸ³é¢‘æ•°æ®æ”¾å…¥é˜Ÿåˆ—
        self.audio_queue.put(indata.copy())
        
        # è®¡ç®—éŸ³é¢‘èƒ½é‡ç”¨äºè°ƒè¯•
        audio_energy = np.mean(np.abs(indata))
        
        # å®æ—¶å£°éŸ³æ£€æµ‹ - å½“æ£€æµ‹åˆ°æ˜æ˜¾å£°éŸ³æ—¶ç«‹å³è¾“å‡ºè°ƒè¯•ä¿¡æ¯
        if audio_energy > 0.05:  # é«˜äºæ­¤é˜ˆå€¼è®¤ä¸ºæœ‰æ˜æ˜¾å£°éŸ³
            print(f"ğŸ¤ [å®æ—¶æ£€æµ‹] æ£€æµ‹åˆ°å£°éŸ³! èƒ½é‡: {audio_energy:.4f} | é™éŸ³è®¡æ•°: {self.silence_counter}")
            
            # æ ¹æ®èƒ½é‡çº§åˆ«ç»™å‡ºå…·ä½“æç¤º
            if audio_energy > 0.2:
                print("ğŸ”Š [å£°éŸ³å¼ºåº¦] å¼ºå£°éŸ³è¾“å…¥!")
            elif audio_energy > 0.1:
                print("ğŸ”Š [å£°éŸ³å¼ºåº¦] ä¸­ç­‰å£°éŸ³è¾“å…¥")
            else:
                print("ğŸ”Š [å£°éŸ³å¼ºåº¦] è½»å¾®å£°éŸ³è¾“å…¥")
                
        elif audio_energy > 0.01:  # ä½èƒ½é‡åŒºé—´ï¼Œå‡å°‘è¾“å‡ºé¢‘ç‡
            # åªåœ¨æ¯100æ¬¡æ£€æµ‹ä¸­è¾“å‡ºä¸€æ¬¡ï¼Œé¿å…åˆ·å±
            if not hasattr(self, '_low_energy_counter'):
                self._low_energy_counter = 0
            self._low_energy_counter += 1
            
            if self._low_energy_counter % 100 == 0:
                print(f"ğŸ”‡ [èƒŒæ™¯éŸ³] æ£€æµ‹åˆ°ä½èƒ½é‡èƒŒæ™¯éŸ³: {audio_energy:.4f}")
                
        # é™éŸ³çŠ¶æ€æç¤º
        if self._detect_silence(indata) and hasattr(self, '_last_sound_time') and (time.time() - getattr(self, '_last_sound_time', 0)) > 3.0:
            if not hasattr(self, '_silence_reported'):
                self._silence_reported = True
                print("ğŸ”‡ [é™éŸ³çŠ¶æ€] å½“å‰ä¸ºé™éŸ³çŠ¶æ€")
        else:
            self._silence_reported = False
            self._last_sound_time = time.time()
        
        # æ£€æµ‹é™éŸ³
        if self._detect_silence(indata):
            self.silence_counter += 1
            self.silence_buffer.append(indata.copy())
        else:
            # æœ‰å£°éŸ³ï¼Œé‡ç½®é™éŸ³è®¡æ•°å™¨
            if self.silence_counter > 0:
                self.audio_buffer.extend(self.silence_buffer)
                self.silence_buffer = []
            self.silence_counter = 0
            self.audio_buffer.append(indata.copy())
            self.last_sound_time = time.time()
    
    def start_recording(self):
        """å¼€å§‹å½•åˆ¶"""
        if self.is_recording:
            return
        
        self.is_recording = True
        self.audio_buffer = []
        self.silence_buffer = []
        self.silence_counter = 0
        self.recording_start_time = time.time()
        self.last_sound_time = time.time()
        
        # å¯åŠ¨éŸ³é¢‘æµ
        try:
            # æ„å»ºæµå‚æ•°
            stream_params = {
                'samplerate': self.sample_rate,
                'channels': self.channels,
                'callback': self._audio_callback,
                'blocksize': self.chunk_size,
                'dtype': np.float32
            }
            
            # å¦‚æœæŒ‡å®šäº†è¾“å…¥è®¾å¤‡ï¼Œæ·»åŠ è®¾å¤‡å‚æ•°
            if self.input_device is not None:
                stream_params['device'] = self.input_device
                logger.info(f"ä½¿ç”¨æŒ‡å®šçš„è¾“å…¥è®¾å¤‡: {self.input_device}")
            else:
                logger.info("ä½¿ç”¨é»˜è®¤è¾“å…¥è®¾å¤‡")
            
            self.stream = sd.InputStream(**stream_params)
            self.stream.start()
        except Exception as e:
            self.is_recording = False
            logger.error(f"å¯åŠ¨éŸ³é¢‘æµå¤±è´¥: {str(e)}")
    
    def stop_recording(self) -> Optional[np.ndarray]:
        """åœæ­¢å½•åˆ¶å¹¶è¿”å›éŸ³é¢‘æ•°æ®"""
        if not self.is_recording:
            logger.warning("æ²¡æœ‰åœ¨å½•åˆ¶ä¸­")
            return None
        
        logger.info("ğŸ›‘ åœæ­¢å½•åˆ¶éŸ³é¢‘")
        
        # åœæ­¢éŸ³é¢‘æµ
        try:
            self.stream.stop()
            self.stream.close()
        except Exception as e:
            logger.error(f"åœæ­¢éŸ³é¢‘æµå¤±è´¥: {str(e)}")
        
        self.is_recording = False
        
        # ç­‰å¾…å‰©ä½™éŸ³é¢‘æ•°æ®å¤„ç†
        time.sleep(0.1)
        
        # åˆå¹¶æ‰€æœ‰éŸ³é¢‘æ•°æ®
        if self.audio_buffer:
            full_audio = np.concatenate(self.audio_buffer, axis=0)
            recording_duration = time.time() - self.recording_start_time
            logger.info(f"å½•åˆ¶å®Œæˆï¼Œæ—¶é•¿: {recording_duration:.2f}ç§’ï¼ŒéŸ³é¢‘é•¿åº¦: {len(full_audio)}")
            return full_audio
        
        return None
    
    def should_stop_recording(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥åœæ­¢å½•åˆ¶"""
        if not self.is_recording:
            return False
        
        # æ£€æŸ¥æœ€å°å½•åˆ¶æ—¶é—´
        current_duration = time.time() - self.recording_start_time
        if current_duration < self.min_recording_duration:
            return False
        
        # æ£€æŸ¥é™éŸ³æŒç»­æ—¶é—´ - å¢åŠ é˜²è¯¯è§¦æœºåˆ¶
        silence_duration = self.silence_counter * self.chunk_duration
        
        # åªæœ‰å½“é™éŸ³æŒç»­æ—¶é—´è¶³å¤Ÿé•¿æ—¶æ‰åœæ­¢
        if silence_duration >= self.silence_duration:
            # é¢å¤–æ£€æŸ¥ï¼šç¡®ä¿éŸ³é¢‘ç¼“å†²åŒºä¸ä¸ºç©ºï¼ˆæœ‰å®é™…éŸ³é¢‘å†…å®¹ï¼‰
            if len(self.audio_buffer) > 0:
                logger.info(f"æ£€æµ‹åˆ°é™éŸ³ {silence_duration:.1f}ç§’ï¼Œåœæ­¢å½•åˆ¶")
                return True
            else:
                # å¦‚æœæ²¡æœ‰éŸ³é¢‘å†…å®¹ï¼Œé‡ç½®é™éŸ³è®¡æ•°å™¨
                self.silence_counter = 0
                return False
        
        return False
    
    def get_recording_status(self) -> Dict[str, Any]:
        """è·å–å½•åˆ¶çŠ¶æ€"""
        return {
            'is_recording': self.is_recording,
            'duration': time.time() - self.recording_start_time if self.is_recording else 0,
            'silence_counter': self.silence_counter,
            'buffer_size': len(self.audio_buffer)
        }

class ProductionSpeechRecognizer:
    """æ­£å¼ç‰ˆè¯­éŸ³è¯†åˆ«å™¨ - ä½¿ç”¨Whisper"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.model = None
        self.sample_rate = config.get('sample_rate', 16000)
        self.model_name = config.get('model_name', 'small')
        self.vad_threshold = config.get('vad_threshold', 0.3)  # è¯­éŸ³æ´»åŠ¨æ£€æµ‹é˜ˆå€¼
        self.min_audio_length = config.get('min_audio_length', 1.0)  # æœ€å°éŸ³é¢‘é•¿åº¦ï¼ˆç§’ï¼‰
        
        try:
            logger.info(f"åŠ è½½Whisperæ¨¡å‹: {self.model_name}")
            
            # ä¸´æ—¶ä¿å­˜ç¯å¢ƒå˜é‡
            old_cc = os.environ.get('CC')
            old_cxx = os.environ.get('CXX')
            
            # ä¸´æ—¶å–æ¶ˆCCå’ŒCXXç¯å¢ƒå˜é‡ï¼Œé¿å…Whisperç¼–è¯‘é”™è¯¯
            if 'CC' in os.environ:
                del os.environ['CC']
            if 'CXX' in os.environ:
                del os.environ['CXX']
            
            try:
                self.model = whisper.load_model(self.model_name)
                logger.info("âœ… Whisperæ¨¡å‹åŠ è½½æˆåŠŸ")
            finally:
                # æ¢å¤ç¯å¢ƒå˜é‡
                if old_cc:
                    os.environ['CC'] = old_cc
                if old_cxx:
                    os.environ['CXX'] = old_cxx
                    
        except Exception as e:
            logger.error(f"âŒ Whisperæ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            self.model = None
    
    def _recognize_wake_word_only(self, audio_data: np.ndarray) -> Optional[RecognitionResult]:
        """ç®€åŒ–çš„å”¤é†’è¯æ£€æµ‹ - ä»…ç”¨äºTTSæ‰“æ–­ï¼Œè·³è¿‡VADè¿‡æ»¤ä»¥æé«˜æ€§èƒ½"""
        if self.model is None:
            return None
        
        # ç®€å•çš„èƒ½é‡æ£€æŸ¥ï¼Œåªè¿‡æ»¤æ˜æ˜¾çš„å™ªå£°
        audio_energy = np.mean(np.abs(audio_data))
        if audio_energy < 0.0005:  # è¿›ä¸€æ­¥é™ä½èƒ½é‡é˜ˆå€¼
            return None
        
        try:
            # ç¡®ä¿éŸ³é¢‘æ•°æ®æ˜¯ä¸€ç»´çš„
            if len(audio_data.shape) > 1:
                audio_data = audio_data.flatten()
            
            # Whisperéœ€è¦æµ®ç‚¹æ•°éŸ³é¢‘æ•°æ®
            if audio_data.dtype != np.float32:
                audio_data = audio_data.astype(np.float32)
            
            # é‡é‡‡æ ·åˆ°16000Hz
            if self.sample_rate != 16000:
                import librosa
                audio_data = librosa.resample(audio_data, orig_sr=self.sample_rate, target_sr=16000)
            
            # ä½¿ç”¨Whisperè¿›è¡Œå¿«é€Ÿè¯†åˆ«
            result = self.model.transcribe(
                audio_data,
                language="zh",
                temperature=0.0,
                beam_size=1,  # ä½¿ç”¨è¾ƒå°beam_sizeæé«˜é€Ÿåº¦
                fp16=False,
                verbose=False
            )
            
            text = result.get("text", "").strip()
            if text:
                return RecognitionResult(text=text, confidence=0.8)
            
        except Exception as e:
            # é™é»˜å¤„ç†é”™è¯¯ï¼Œé¿å…å¤§é‡è°ƒè¯•è¾“å‡º
            pass
        
        return None
    
    def recognize_audio(self, audio_data: np.ndarray) -> Optional[RecognitionResult]:
        """è¯†åˆ«éŸ³é¢‘ - å¸¦è¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼ˆæè‡´æ€§èƒ½ä¼˜åŒ–ç‰ˆï¼‰"""
        if self.model is None:
            logger.error("Whisperä¸å¯ç”¨")
            return None
        
        # è®¡ç®—éŸ³é¢‘é•¿åº¦
        audio_duration = len(audio_data) / self.sample_rate
        
        # å¿«é€Ÿè¯­éŸ³æ´»åŠ¨æ£€æµ‹
        if audio_duration < self.min_audio_length:
            return None
        
        # å¿«é€Ÿèƒ½é‡æ£€æµ‹
        audio_energy = np.mean(np.abs(audio_data))
        if audio_energy < self.vad_threshold:
            return None
        
        # é€‚åº¦çš„éŸ³é¢‘é•¿åº¦é™åˆ¶ä»¥ä¼˜åŒ–æ€§èƒ½ï¼Œä¿æŒè¯†åˆ«ç²¾åº¦
        max_audio_duration = 8.0  # æœ€å¤šå¤„ç†8ç§’éŸ³é¢‘
        if audio_duration > max_audio_duration:
            # æˆªå–éŸ³é¢‘
            max_samples = int(max_audio_duration * self.sample_rate)
            audio_data = audio_data[:max_samples]
            audio_duration = max_audio_duration
            print(f"ğŸ” [ASRä¼˜åŒ–] æˆªå–éŸ³é¢‘åˆ° {max_audio_duration} ç§’ä»¥ä¼˜åŒ–æ€§èƒ½")
        
        try:
            start_time = time.time()
            
            print(f"ğŸ” [ASRè¯¦æƒ…] éŸ³é¢‘å½¢çŠ¶: {audio_data.shape}, é‡‡æ ·ç‡: {self.sample_rate}")
            
            logger.info(f"å¼€å§‹è¯†åˆ«éŸ³é¢‘ (é•¿åº¦: {audio_duration:.2f}ç§’, èƒ½é‡: {audio_energy:.3f})...")
            
            # ä¸´æ—¶ä¿å­˜å’Œæ¸…é™¤ç¯å¢ƒå˜é‡ï¼Œé¿å…Tritonç¼–è¯‘é”™è¯¯
            old_cc = os.environ.get('CC')
            old_cxx = os.environ.get('CXX')
            
            if 'CC' in os.environ:
                del os.environ['CC']
            if 'CXX' in os.environ:
                del os.environ['CXX']
            
            try:
                # ç¡®ä¿éŸ³é¢‘æ•°æ®æ˜¯ä¸€ç»´çš„
                if len(audio_data.shape) > 1:
                    audio_data = audio_data.flatten()
                
                print(f"ğŸ” [ASRè¯¦æƒ…] éŸ³é¢‘å½¢çŠ¶: {audio_data.shape}, é‡‡æ ·ç‡: {self.sample_rate}")
                
                # Whisperéœ€è¦æµ®ç‚¹æ•°éŸ³é¢‘æ•°æ®ï¼Œç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
                if audio_data.dtype != np.float32:
                    audio_data = audio_data.astype(np.float32)
                
                # Whisperé»˜è®¤ä½¿ç”¨16000Hzé‡‡æ ·ç‡ï¼Œéœ€è¦é‡é‡‡æ ·
                if self.sample_rate != 16000:
                    import librosa
                    audio_data = librosa.resample(audio_data, orig_sr=self.sample_rate, target_sr=16000)
                    print(f"ğŸ” [ASRè¯¦æƒ…] éŸ³é¢‘å·²é‡é‡‡æ ·åˆ°16000Hzï¼Œæ–°å½¢çŠ¶: {audio_data.shape}")
                
                # çœŸæ­£èƒ½æå‡æ€§èƒ½çš„å‚æ•°ç»„åˆ
                result = self.model.transcribe(
                    audio_data,
                    language='zh',
                    fp16=False,
                    verbose=False,
                    # æ€§èƒ½ä¼˜åŒ–å‚æ•° - åŸºäºæµ‹è¯•ç»“æœ
                    temperature=0.0,  # ç¡®å®šæ€§è¾“å‡º
                    beam_size=1,  # æœ€å°beam sizeæå‡é€Ÿåº¦
                    patience=0.0,  # æ— è€å¿ƒç­‰å¾…
                    best_of=1,  # å•ä¸ªå€™é€‰æœ€å¿«
                    # ç²¾ç®€å‚æ•°
                    initial_prompt="å¤¸çˆ¶",  # æœ€ç®€æç¤ºè¯
                    suppress_tokens=[],  # ä¸æŠ‘åˆ¶ä»»ä½•token
                    # ç¦ç”¨æ‰€æœ‰é¢å¤–åŠŸèƒ½
                    word_timestamps=False,
                    # å®½æ¾å‚æ•°
                    compression_ratio_threshold=3.0,  # å®½æ¾å‹ç¼©ç‡
                    logprob_threshold=-2.0,  # å®½æ¾æ¦‚ç‡é˜ˆå€¼
                    no_speech_threshold=0.8,  # å®½æ¾è¯­éŸ³æ£€æµ‹
                    condition_on_previous_text=False,  # ä¸ä¾èµ–å‰é¢çš„æ–‡æœ¬
                    task="transcribe"  # æ˜ç¡®è½¬å½•ä»»åŠ¡
                )
            finally:
                # æ¢å¤ç¯å¢ƒå˜é‡
                if old_cc:
                    os.environ['CC'] = old_cc
                if old_cxx:
                    os.environ['CXX'] = old_cxx
            
            recognized_text = result['text'].strip()
            duration = time.time() - start_time
            
            # å¦‚æœè¯†åˆ«ç»“æœä¸ºç©ºï¼Œè¿”å›None
            if not recognized_text:
                logger.info("è¯†åˆ«ç»“æœä¸ºç©º")
                return None
            
            # è®¡ç®—ç½®ä¿¡åº¦ï¼ˆåŸºäºè¯†åˆ«æ—¶é•¿å’ŒéŸ³é¢‘é•¿åº¦ï¼‰
            confidence = min(1.0, len(recognized_text) / max(audio_duration * 2, 1) * (1.0 / max(duration, 0.1)))
            
            logger.info(f"è¯†åˆ«ç»“æœ: '{recognized_text}'")
            logger.info(f"è¯†åˆ«è€—æ—¶: {duration:.2f}ç§’, ç½®ä¿¡åº¦: {confidence:.3f}")
            
            return RecognitionResult(
                text=recognized_text,
                confidence=confidence,
                duration=duration,
                engine="whisper_small"
            )
            
        except Exception as e:
            print(f"âŒ [ASRé”™è¯¯] è¯†åˆ«å¤±è´¥: {str(e)}")
            import traceback
            print(f"âŒ [ASRé”™è¯¯è¯¦æƒ…] {traceback.format_exc()}")
            logger.error(f"éŸ³é¢‘è¯†åˆ«å¤±è´¥: {str(e)}")
            return None

class ProductionLLMProcessor:
    """æ­£å¼ç‰ˆLLMå¤„ç†å™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.engine_type = config.get('engine_type', 'zhipuai')
        self.max_tokens = config.get('max_tokens', 100)
        self.temperature = config.get('temperature', 0.1)
        self.timeout = config.get('timeout', 5.0)
        
        # æ™ºèƒ½ç¼“å­˜
        self.cache = {}
        self.cache_timeout = config.get('cache_timeout', 300)  # 5åˆ†é’Ÿ
        
        logger.info(f"åˆå§‹åŒ–LLMå¤„ç†å™¨: {self.engine_type}")
    
    def _get_cache_key(self, text: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        import hashlib
        return hashlib.md5(text.encode('utf-8')).hexdigest()
    
    def _is_cache_valid(self, cache_entry: Dict) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        return (time.time() - cache_entry['timestamp']) < self.cache_timeout
    
    async def _call_llm_for_intent(self, text: str) -> Tuple[str, float, Dict[str, Any]]:
        """è°ƒç”¨LLMè¿›è¡Œæ„å›¾åˆ†æ"""
        if self.engine_type == 'zhipuai':
            return await self._call_zhipuai_llm(text)
        else:
            # é»˜è®¤å›é€€åˆ°å…³é”®è¯åŒ¹é…
            return self._classify_intent(text)
    
    async def _call_zhipuai_llm(self, text: str) -> Tuple[str, float, Dict[str, Any]]:
        """è°ƒç”¨æ™ºè°±AIè¿›è¡Œæ„å›¾åˆ†æå’Œå¯¹è¯"""
        print(f"ğŸ” [DEBUG] å¼€å§‹è°ƒç”¨æ™ºè°±AI LLM API...")
        try:
            import httpx
            
            # ä»é…ç½®æ–‡ä»¶è·å–APIå¯†é’¥
            config_path = os.path.join(os.path.dirname(__file__), '..', 'config', 'llm_params.yaml')
            api_key = None
            
            # ä»é…ç½®æ–‡ä»¶è¯»å–APIå¯†é’¥
            try:
                import yaml
                if os.path.exists(config_path):
                    with open(config_path, 'r', encoding='utf-8') as f:
                        config_data = yaml.safe_load(f)
                        if config_data and 'zhipuai' in config_data:
                            api_key = config_data['zhipuai'].get('api_key')
                            if not api_key:
                                logger.warning("é…ç½®æ–‡ä»¶ä¸­æœªæ‰¾åˆ°APIå¯†é’¥")
                        else:
                            logger.warning("é…ç½®æ–‡ä»¶ä¸­æœªæ‰¾åˆ°zhipuaié…ç½®")
                else:
                    logger.warning("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
            except Exception as e:
                logger.error(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            
            if not api_key:
                logger.error("æœªæ‰¾åˆ°APIå¯†é’¥")
                print(f"âŒ [DEBUG] æœªæ‰¾åˆ°APIå¯†é’¥ï¼Œå›é€€åˆ°å…³é”®è¯åŒ¹é…")
                return self._classify_intent(text)
            
            # æç®€ç³»ç»Ÿæç¤ºè¯ä»¥è·å¾—æœ€å¿«é€Ÿåº¦
            system_prompt = """ä½ æ˜¯å¤¸çˆ¶æœºå™¨äººã€‚æ”¯æŒï¼šwaveã€welcomeã€stopã€‚

è§„åˆ™ï¼š
- åŠ¨ä½œè¯·æ±‚ï¼šcommandç±»å‹
- å…¶ä»–ï¼šconversationç±»å‹

JSONæ ¼å¼ï¼š
{
  "type": "command|conversation",
  "intent": "wave|welcome|stop|conversation", 
  "confidence": 0.8,
  "response": "å›åº”",
  "instruction": "wave|welcome|stop|none"
}

åªè¿”å›JSONã€‚"""
            
            # æ„å»ºè¯·æ±‚
            url = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }
            # ä»é…ç½®æ–‡ä»¶è¯»å–æ¨¡å‹è®¾ç½®
            model_name = None
            try:
                if os.path.exists(config_path):
                    with open(config_path, 'r', encoding='utf-8') as f:
                        config_data = yaml.safe_load(f)
                        if config_data and 'zhipuai' in config_data:
                            model_name = config_data['zhipuai'].get('model')
                            if not model_name:
                                logger.warning("é…ç½®æ–‡ä»¶ä¸­æœªæ‰¾åˆ°æ¨¡å‹è®¾ç½®")
                        else:
                            logger.warning("é…ç½®æ–‡ä»¶ä¸­æœªæ‰¾åˆ°zhipuaié…ç½®")
                else:
                    logger.warning("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
            except Exception as e:
                logger.error(f"è¯»å–æ¨¡å‹é…ç½®å¤±è´¥: {e}")
            
            if not model_name:
                logger.error("æœªæ‰¾åˆ°æ¨¡å‹é…ç½®")
                print(f"âŒ [DEBUG] æœªæ‰¾åˆ°æ¨¡å‹é…ç½®ï¼Œå›é€€åˆ°å…³é”®è¯åŒ¹é…")
                return self._classify_intent(text)
            
            data = {
                "model": model_name,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": text}
                ],
                "max_tokens": 300,  # ç¡®ä¿èƒ½ç”Ÿæˆå®Œæ•´çš„JSONå“åº”
                "temperature": 0.3
            }
            
            # æè‡´å‡å°‘è¶…æ—¶æ—¶é—´ä»¥æé«˜å“åº”é€Ÿåº¦
            timeout = httpx.Timeout(
                connect=3.0,    # è¿æ¥è¶…æ—¶3ç§’
                read=8.0,       # è¯»å–è¶…æ—¶8ç§’
                write=3.0,      # å†™å…¥è¶…æ—¶3ç§’
                pool=5.0        # è¿æ¥æ± è¶…æ—¶5ç§’
            )
            
            async with httpx.AsyncClient(timeout=timeout) as client:
                response = await client.post(url, headers=headers, json=data)
                
                if response.status_code == 200:
                    result = response.json()
                    content = result['choices'][0]['message']['content']
                    
                    # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼Œæ˜¾ç¤ºAPIè¿”å›çš„åŸå§‹æ•°æ®
                    print(f"ğŸ” [DEBUG] LLM APIåŸå§‹è¿”å›æ•°æ®:")
                    print(f"   çŠ¶æ€ç : {response.status_code}")
                    print(f"   è¿”å›å†…å®¹: {content}")
                    logger.info(f"[DEBUG] LLM APIåŸå§‹è¿”å›: {content}")
                    
                    # è§£æJSONå“åº”
                    try:
                        import json
                        llm_result = json.loads(content.strip())
                        
                        # è§£ææ–°çš„è¿”å›æ ¼å¼
                        response_type = llm_result.get('type', 'conversation')
                        intent = llm_result.get('intent', 'conversation')
                        confidence = llm_result.get('confidence', 0.5)
                        response_text = llm_result.get('response', 'æŠ±æ­‰ï¼Œæˆ‘ä¸å¤ªç†è§£æ‚¨çš„è¯·æ±‚ã€‚')
                        instruction = llm_result.get('instruction', 'none')
                        
                        # æ ¹æ®ç±»å‹å†³å®šåŠ¨ä½œç±»å‹
                        if response_type == 'command' and intent in ['wave', 'welcome']:
                            action_type = intent  # æ‰§è¡Œæœºå™¨äººåŠ¨ä½œ
                        else:
                            action_type = 'response'  # ä»…å¯¹è¯å›åº”
                        
                        # æ„å»ºåŠ¨ä½œ
                        action = {
                            'type': action_type,
                            'text': response_text,
                            'response_type': response_type,
                            'json_response': {
                                'intent': intent,
                                'confidence': confidence,
                                'instruction': instruction,
                                'response': response_text,
                                'action': action_type,
                                'timestamp': time.time()
                            }
                        }
                        
                        # è®°å½•ä¸åŒç±»å‹çš„å¤„ç†
                        if response_type == 'command':
                            logger.info(f"ğŸ¤– æŒ‡ä»¤æ‰§è¡Œ: {intent} -> {instruction}")
                        else:
                            logger.info(f"ğŸ’¬ å¯¹è¯å›åº”: {response_text[:50]}...")
                        
                        return intent, confidence, action
                        
                    except json.JSONDecodeError as e:
                        logger.error(f"LLMè¿”å›çš„JSONè§£æå¤±è´¥: {content}")
                        print(f"âŒ [DEBUG] JSONè§£æå¤±è´¥: {e}")
                        print(f"âŒ [DEBUG] åŸå§‹å†…å®¹: {content}")
                        
                        # å°è¯•ä¿®å¤è¢«æˆªæ–­çš„JSON
                        try:
                            # æ›´æ™ºèƒ½çš„JSONä¿®å¤
                            fixed_content = self._fix_json_content(content)
                            if fixed_content:
                                print(f"ğŸ”§ [DEBUG] ä¿®å¤åçš„JSON: {fixed_content}")
                                llm_result = json.loads(fixed_content)
                                
                                # è§£æä¿®å¤åçš„JSON
                                response_type = llm_result.get('type', 'conversation')
                                intent = llm_result.get('intent', 'conversation')
                                confidence = llm_result.get('confidence', 0.5)
                                response_text = llm_result.get('response', 'æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰ç†è§£æ‚¨çš„è¯·æ±‚ã€‚è¯·å°è¯•ç”¨æ›´æ¸…æ™°çš„è¯­è¨€è¡¨è¾¾ã€‚')
                                instruction = llm_result.get('instruction', 'none')
                                
                                # å¦‚æœresponseå­—æ®µä¸å®Œæ•´ï¼Œå°è¯•ä»contentä¸­æå–
                                if response_text.endswith('...') or len(response_text) < 10:
                                    response_text = "æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›æŠ€æœ¯é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚"
                                
                                # æ ¹æ®ç±»å‹å†³å®šåŠ¨ä½œç±»å‹
                                if response_type == 'command' and intent in ['wave', 'welcome']:
                                    action_type = intent  # æ‰§è¡Œæœºå™¨äººåŠ¨ä½œ
                                else:
                                    action_type = 'response'  # ä»…å¯¹è¯å›åº”
                                
                                # æ„å»ºåŠ¨ä½œ
                                action = {
                                    'type': action_type,
                                    'text': response_text,
                                    'response_type': response_type,
                                    'json_response': {
                                        'intent': intent,
                                        'confidence': confidence,
                                        'instruction': instruction,
                                        'response': response_text,
                                        'action': action_type,
                                        'timestamp': time.time()
                                    }
                                }
                                
                                logger.info(f"ğŸ”§ JSONä¿®å¤æˆåŠŸï¼Œä½¿ç”¨ä¿®å¤åçš„ç»“æœ")
                                return intent, confidence, action
                        except Exception as fix_e:
                            logger.error(f"JSONä¿®å¤å¤±è´¥: {fix_e}")
                            print(f"âŒ [DEBUG] JSONä¿®å¤å¤±è´¥: {fix_e}")
                        
                        return self._classify_intent(text)
                        
                else:
                    error_msg = response.text if response.text else "æœªçŸ¥é”™è¯¯"
                    logger.error(f"LLM APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                    print(f"âŒ [DEBUG] APIè°ƒç”¨å¤±è´¥:")
                    print(f"   çŠ¶æ€ç : {response.status_code}")
                    print(f"   é”™è¯¯ä¿¡æ¯: {error_msg}")
                    return self._classify_intent(text)
                    
        except Exception as e:
            logger.error(f"LLMè°ƒç”¨å¼‚å¸¸: {str(e)}")
            print(f"âŒ [DEBUG] LLMè°ƒç”¨å¼‚å¸¸: {str(e)}")
            import traceback
            print(f"âŒ [DEBUG] å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
            return self._classify_intent(text)
    
    async def process_text_async(self, text: str) -> IntentResult:
        """å¼‚æ­¥å¤„ç†æ–‡æœ¬"""
        start_time = time.time()
        
        # ä¸´æ—¶ç¦ç”¨ç¼“å­˜ä»¥ç¡®ä¿ä½¿ç”¨æ–°çš„ç³»ç»Ÿæç¤ºè¯
        logger.info(f"ğŸ”„ è·³è¿‡ç¼“å­˜ï¼Œç›´æ¥è°ƒç”¨LLM: '{text[:30]}...'")
        
        # ç”Ÿæˆç¼“å­˜é”®ç”¨äºåç»­ç¼“å­˜
        cache_key = self._get_cache_key(text)
        
        try:
            # ä½¿ç”¨LLMè¿›è¡Œæ„å›¾åˆ†æ
            intent, confidence, action = await self._call_llm_for_intent(text)
            
            # æ›´æ–°ç¼“å­˜
            self.cache[cache_key] = {
                'intent': intent,
                'confidence': confidence,
                'action': action,
                'timestamp': time.time()
            }
            
            processing_time = time.time() - start_time
            
            logger.info(f"LLMå¤„ç†ç»“æœ: {intent}, ç½®ä¿¡åº¦: {confidence:.2f}, è€—æ—¶: {processing_time:.2f}ç§’")
            
            return IntentResult(
                intent=intent,
                confidence=confidence,
                action=action,
                processing_time=processing_time
            )
            
        except Exception as e:
            logger.error(f"LLMå¤„ç†å¤±è´¥: {str(e)}")
            return IntentResult(
                intent="unknown",
                confidence=0.0,
                action={},
                processing_time=time.time() - start_time
            )
    
    def _fix_json_content(self, content: str) -> Optional[str]:
        """å°è¯•ä¿®å¤ä¸å®Œæ•´çš„JSONå†…å®¹"""
        try:
            # åŸºç¡€æ¸…ç†
            content = content.strip()
            
            # å¦‚æœå·²ç»æ˜¯æœ‰æ•ˆçš„JSONï¼Œç›´æ¥è¿”å›
            json.loads(content)
            return content
        except:
            pass
        
        try:
            # ç­–ç•¥1: æŸ¥æ‰¾æœ€åä¸€ä¸ªå®Œæ•´çš„JSONå¯¹è±¡
            last_brace = content.rfind('}')
            if last_brace != -1:
                first_brace = content.find('{')
                if first_brace != -1 and first_brace < last_brace:
                    candidate = content[first_brace:last_brace + 1]
                    try:
                        json.loads(candidate)
                        return candidate
                    except:
                        pass
            
            # ç­–ç•¥2: ä¿®å¤ç¼ºå¤±çš„å¼•å·
            lines = content.split('\n')
            fixed_lines = []
            for line in lines:
                line = line.strip()
                if line and not line.endswith(','):
                    # æ£€æŸ¥æ˜¯å¦æ˜¯å­—ç¬¦ä¸²å­—æ®µä½†ç¼ºå°‘ç»“æŸå¼•å·
                    if ':' in line and line.count('"') == 1:
                        parts = line.split(':', 1)
                        if len(parts) == 2:
                            key = parts[0].strip()
                            value = parts[1].strip()
                            if value and value[0] == '"' and value[-1] != '"':
                                value += '"'
                                line = f'{key}: {value}'
                fixed_lines.append(line)
            
            candidate = '\n'.join(fixed_lines)
            # ç¡®ä¿JSONä»¥}ç»“æŸ
            if not candidate.endswith('}'):
                candidate += '}'
            
            try:
                json.loads(candidate)
                return candidate
            except:
                pass
            
            # ç­–ç•¥3: åˆ›å»ºæœ€å°åŒ–çš„JSON
            if '"response"' in content:
                # æå–responseå­—æ®µçš„å†…å®¹
                response_start = content.find('"response"')
                if response_start != -1:
                    response_part = content[response_start:]
                    value_start = response_part.find(':')
                    if value_start != -1:
                        value_part = response_part[value_start + 1:].strip()
                        if value_part.startswith('"'):
                            # æ‰¾åˆ°å­—ç¬¦ä¸²ç»“æŸä½ç½®ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ™ä½¿ç”¨ä¸‹ä¸€ä¸ªå¼•å·
                            quote_end = value_part.find('"', 1)
                            if quote_end == -1:
                                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç»“æŸå¼•å·ï¼Œå–åˆ°è¡Œå°¾æˆ–æœ€åä¸€ä¸ªå­—ç¬¦
                                line_end = value_part.find('\n')
                                if line_end != -1:
                                    quote_end = line_end
                                else:
                                    quote_end = len(value_part) - 1
                            
                            if quote_end > 1:
                                response_text = value_part[1:quote_end]
                                # æ¸…ç†å“åº”æ–‡æœ¬
                                response_text = response_text.strip().rstrip('ï¼Œã€‚ï¼ï¼Ÿ,.!?')
                                if len(response_text) > 0:
                                    # åˆ›å»ºç®€å•çš„JSON
                                    simple_json = f'{{"type": "conversation", "intent": "conversation", "confidence": 0.8, "response": "{response_text}", "instruction": "none"}}'
                                    try:
                                        json.loads(simple_json)
                                        print(f"ğŸ”§ [DEBUG] æˆåŠŸåˆ›å»ºç®€åŒ–JSON: {simple_json}")
                                        return simple_json
                                    except:
                                        pass
            
            return None
            
        except Exception as e:
            print(f"ğŸ”§ [DEBUG] JSONä¿®å¤å¤±è´¥: {e}")
            return None
    
    def _classify_intent(self, text: str) -> Tuple[str, float, Dict[str, Any]]:
        """åˆ†ç±»æ„å›¾ - ä½¿ç”¨JSONé…ç½®æ–‡ä»¶"""
        text = text.lower().strip()
        
        # åŠ è½½æ„å›¾é…ç½®
        intent_config_path = os.path.join(os.path.dirname(__file__), '..', 'config', 'intent_patterns.json')
        intent_config = {}
        
        try:
            if os.path.exists(intent_config_path):
                with open(intent_config_path, 'r', encoding='utf-8') as f:
                    intent_config = json.load(f)
        except Exception as e:
            logger.error(f"åŠ è½½æ„å›¾é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
        
        best_intent = "unknown"
        best_confidence = 0.0
        best_action = {}
        
        # éå†æ‰€æœ‰æ„å›¾
        for intent_key, intent_data in intent_config.get('intents', {}).items():
            patterns = intent_data.get('patterns', [])
            confidence_threshold = intent_data.get('confidence_threshold', 0.0)
            
            # è®¡ç®—åŒ¹é…åº¦
            match_count = sum(1 for pattern in patterns if pattern in text)
            confidence = match_count / len(patterns) if patterns else 0.0
            
            # å¦‚æœåŒ¹é…åˆ°äº†å…³é”®è¯ï¼Œæé«˜ç½®ä¿¡åº¦
            if match_count > 0:
                confidence = max(confidence, 0.8)  # è‡³å°‘0.8çš„ç½®ä¿¡åº¦
            
            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é˜ˆå€¼
            if confidence > best_confidence and confidence >= confidence_threshold:
                best_confidence = confidence
                best_intent = intent_key
                
                # è·å–æ„å›¾é…ç½®
                response_text = intent_data.get('response', '')
                action_config = intent_data.get('action', {})
                json_response_config = intent_data.get('json_response', {})
                
                # æ›´æ–°JSONå“åº”ä¸­çš„æ—¶é—´æˆ³
                json_response_config['timestamp'] = time.time()
                json_response_config['confidence'] = confidence
                
                # æ„å»ºåŠ¨ä½œ
                best_action = {
                    'type': action_config.get('type', 'response'),
                    'text': response_text,
                    'json_response': json_response_config
                }
                
                # æ·»åŠ å…¶ä»–åŠ¨ä½œå‚æ•°
                for key, value in action_config.items():
                    if key != 'type':
                        best_action[key] = value
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•æ„å›¾ï¼Œä½¿ç”¨é»˜è®¤çš„unknownæ„å›¾
        if best_confidence == 0.0:
            unknown_intent = intent_config.get('intents', {}).get('unknown', {})
            best_action = {
                'type': 'response',
                'text': unknown_intent.get('response', 'æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰ç†è§£æ‚¨çš„è¯·æ±‚ã€‚è¯·å°è¯•ç”¨æ›´æ¸…æ™°çš„è¯­è¨€è¡¨è¾¾ã€‚'),
                'json_response': unknown_intent.get('json_response', {})
            }
            best_action['json_response']['timestamp'] = time.time()
            best_action['json_response']['confidence'] = 0.0
        
        return best_intent, best_confidence, best_action

class ProductionSystem:
    """æ­£å¼ç‰ˆç³»ç»Ÿ"""
    
    def __init__(self, config: Dict[str, Any], input_mode: str = 'voice'):
        self.config = config
        self.input_mode = input_mode  # voice æˆ– text
        self.audio_mode = config.get('audio_mode', 'microphone')  # microphone æˆ– preset
        
        # åˆå§‹åŒ–ROSç»„ä»¶
        self.publisher = ROSPublisher()
        
        # åˆå§‹åŒ–TTSæ’­æ”¾å™¨
        self.tts_player = MemoryTTSPlayer(self.publisher, config.get('tts', {}))
        
        # åˆå§‹åŒ–ç»„ä»¶ - ç¡®ä¿sample_rateé…ç½®æ­£ç¡®ä¼ é€’
        asr_config = config.get('asr', {})
        speech_config = config.get('speech', {})
        
        # å°†asré…ç½®ä¸­çš„sample_rateä¼ é€’ç»™speeché…ç½®
        if 'sample_rate' in asr_config and 'sample_rate' not in speech_config:
            speech_config['sample_rate'] = asr_config['sample_rate']
        
        self.recorder = AudioRecorder(asr_config)  # ä½¿ç”¨asré…ç½®è€Œä¸æ˜¯audioé…ç½®
        self.speech_recognizer = ProductionSpeechRecognizer(speech_config)
        self.llm_processor = ProductionLLMProcessor(config.get('llm', {}))
        
        # ä¸­æ–­å¤„ç†çŠ¶æ€
        self.pending_wake_word = None
        self.pending_command = None
        
        # ç³»ç»ŸçŠ¶æ€
        self.is_running = False
        self.recording_thread = None
        self.user_input_thread = None
        
        # å½•éŸ³çŠ¶æ€ç®¡ç†ï¼ˆä»…åœ¨è¯­éŸ³æ¨¡å¼ä¸‹ä½¿ç”¨ï¼‰
        self.recording_state = 'IDLE'  # IDLE, WAITING_FOR_WAKE_WORD, LISTENING_FOR_COMMAND, PROCESSING, PLAYING_RESPONSE
        self.wake_word_detected = False
        self.last_processing_time = 0
        self.processing_cooldown = 2.0  # å¤„ç†å†·å´æ—¶é—´2ç§’
        
        # æ€§èƒ½ç»Ÿè®¡
        self.performance_stats = {
            'total_requests': 0,
            'avg_asr_time': 0.0,
            'avg_llm_time': 0.0,
            'avg_tts_generation_time': 0.0,
            'avg_response_time': 0.0,  # ä»è¾“å…¥åˆ°ç³»ç»Ÿå¼€å§‹å“åº”çš„æ—¶é—´
            'min_response_time': float('inf'),
            'max_response_time': 0.0
        }
        
        # è®¾ç½®ä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
        
        logger.info(f"âœ… æ­£å¼ç‰ˆç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ (è¾“å…¥æ¨¡å¼: {self.input_mode})")
    
    def _wake_word_detected_during_tts(self, detected_text: str):
        """TTSæœŸé—´æ£€æµ‹åˆ°å”¤é†’è¯çš„å›è°ƒå‡½æ•°"""
        print(f"ğŸ¯ [ä¸­æ–­] æ£€æµ‹åˆ°å”¤é†’è¯ï¼Œä¸­æ–­TTS: {detected_text}")
        
        # ä¸­æ–­å½“å‰TTSæ’­æ”¾
        self.tts_player.interrupt_playback()
        
        # ä¿å­˜æ£€æµ‹åˆ°çš„å”¤é†’è¯å’Œå‘½ä»¤
        self.pending_wake_word = detected_text
        
        # æå–å‘½ä»¤éƒ¨åˆ†ï¼ˆå»é™¤å”¤é†’è¯ï¼‰
        command_text = detected_text.replace("å¤¸çˆ¶å¤¸çˆ¶", "").strip()
        if command_text:
            self.pending_command = command_text
        else:
            self.pending_command = "wake_word_only"
        
        print(f"ğŸ¯ [ä¸­æ–­] ä¸­æ–­å®Œæˆï¼Œå¾…å¤„ç†: {self.pending_command}")
    
    def _signal_handler(self, signum, frame):
        """ä¿¡å·å¤„ç†å™¨"""
        logger.info(f"æ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨å…³é—­ç³»ç»Ÿ...")
        self._print_performance_summary()
        self.stop()
        sys.exit(0)
    
    def _update_performance_stats(self, asr_time: float, llm_time: float, tts_time: float, response_time: float):
        """æ›´æ–°æ€§èƒ½ç»Ÿè®¡"""
        stats = self.performance_stats
        stats['total_requests'] += 1
        
        # è®¡ç®—ç§»åŠ¨å¹³å‡
        alpha = 0.3  # å¹³æ»‘å› å­
        stats['avg_asr_time'] = (1 - alpha) * stats['avg_asr_time'] + alpha * asr_time
        stats['avg_llm_time'] = (1 - alpha) * stats['avg_llm_time'] + alpha * llm_time
        stats['avg_tts_generation_time'] = (1 - alpha) * stats['avg_tts_generation_time'] + alpha * tts_time
        stats['avg_response_time'] = (1 - alpha) * stats['avg_response_time'] + alpha * response_time
        
        # æ›´æ–°æœ€å€¼
        stats['min_response_time'] = min(stats['min_response_time'], response_time)
        stats['max_response_time'] = max(stats['max_response_time'], response_time)
    
    def _print_performance_summary(self):
        """æ‰“å°æ€§èƒ½ç»Ÿè®¡æ‘˜è¦"""
        stats = self.performance_stats
        if stats['total_requests'] == 0:
            return
        
        print("\n" + "="*60)
        print("ğŸ“Š æ€§èƒ½ç»Ÿè®¡æ‘˜è¦ - è¾“å…¥åˆ°å“åº”æ—¶é—´")
        print("="*60)
        print(f"ğŸ“ˆ æ€»è¯·æ±‚æ•°: {stats['total_requests']}")
        print(f"â±ï¸  å¹³å‡å“åº”æ—¶é—´: {stats['avg_response_time']:.3f}ç§’")
        print(f"â±ï¸  æœ€å¿«å“åº”æ—¶é—´: {stats['min_response_time']:.3f}ç§’")
        print(f"â±ï¸  æœ€æ…¢å“åº”æ—¶é—´: {stats['max_response_time']:.3f}ç§’")
        print(f"ğŸ¤  å¹³å‡ASRæ—¶é—´: {stats['avg_asr_time']:.3f}ç§’")
        print(f"ğŸ§   å¹³å‡LLMæ—¶é—´: {stats['avg_llm_time']:.3f}ç§’")
        print(f"ğŸ”Š  å¹³å‡TTSç”Ÿæˆæ—¶é—´: {stats['avg_tts_generation_time']:.3f}ç§’")
        
        # è®¡ç®—å„é˜¶æ®µå æ¯”
        if stats['avg_response_time'] > 0:
            asr_percent = (stats['avg_asr_time'] / stats['avg_response_time']) * 100
            llm_percent = (stats['avg_llm_time'] / stats['avg_response_time']) * 100
            tts_percent = (stats['avg_tts_generation_time'] / stats['avg_response_time']) * 100
            print(f"ğŸ“Š æ—¶é—´å æ¯” - ASR: {asr_percent:.1f}%, LLM: {llm_percent:.1f}%, TTSç”Ÿæˆ: {tts_percent:.1f}%")
        
        # æ€§èƒ½ä¼˜åŒ–å»ºè®®
        self._provide_performance_recommendations(stats)
        
        print("="*60)
    
    def _provide_performance_recommendations(self, stats: Dict[str, Any]):
        """æä¾›æ€§èƒ½ä¼˜åŒ–å»ºè®®"""
        print("\nğŸ”§ æ€§èƒ½ä¼˜åŒ–å»ºè®®:")
        
        # ASRä¼˜åŒ–å»ºè®®
        if stats['avg_asr_time'] > 2.0:
            print("  ğŸ¤ ASRæ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®:")
            print("    - ä½¿ç”¨æ›´å°çš„Whisperæ¨¡å‹ï¼ˆtinyæˆ–baseï¼‰")
            print("    - å‡å°‘éŸ³é¢‘è¾“å…¥é•¿åº¦")
            print("    - å¯ç”¨éŸ³é¢‘é¢„è¿‡æ»¤")
        
        # LLMä¼˜åŒ–å»ºè®®
        if stats['avg_llm_time'] > 3.0:
            print("  ğŸ§  LLMæ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®:")
            print("    - å‡å°‘max_tokensæ•°é‡")
            print("    - ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹")
            print("    - å¯ç”¨å“åº”ç¼“å­˜")
        
        # TTSä¼˜åŒ–å»ºè®®
        if stats['avg_tts_generation_time'] > 2.0:
            print("  ğŸ”Š TTSç”Ÿæˆæ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®:")
            print("    - ä½¿ç”¨æ›´å¿«çš„TTSå¼•æ“")
            print("    - å‡å°‘å“åº”æ–‡æœ¬é•¿åº¦")
            print("    - é¢„å…ˆç”Ÿæˆå¸¸ç”¨å›åº”")
        
        # æ€»ä½“ä¼˜åŒ–å»ºè®®
        if stats['avg_response_time'] > 5.0:
            print("  âš¡ æ€»ä½“ä¼˜åŒ–å»ºè®®:")
            print("    - è€ƒè™‘ä½¿ç”¨æ›´å¿«çš„ç¡¬ä»¶")
            print("    - å¯ç”¨å¹¶è¡Œå¤„ç†")
            print("    - å®æ–½æµå¼å¤„ç†")
        
        # æ€§èƒ½è¯„çº§ - ç›®æ ‡2-3ç§’
        if stats['avg_response_time'] < 2.0:
            print("  ğŸ† æ€§èƒ½è¯„çº§: ä¼˜ç§€ (< 2ç§’)")
        elif stats['avg_response_time'] < 3.0:
            print("  ğŸ† æ€§èƒ½è¯„çº§: è‰¯å¥½ (2-3ç§’) âœ“ ç›®æ ‡è¾¾æˆ")
        elif stats['avg_response_time'] < 5.0:
            print("  ğŸ† æ€§èƒ½è¯„çº§: ä¸€èˆ¬ (3-5ç§’)")
        else:
            print("  ğŸ† æ€§èƒ½è¯„çº§: éœ€è¦ä¼˜åŒ– (> 5ç§’) âŒ éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
        
        print()
    
    def _recording_loop(self):
        """å½•åˆ¶å¾ªç¯ - å¸¦çŠ¶æ€ç®¡ç†å’Œå”¤é†’è¯æ£€æµ‹"""
        logger.info("ğŸ”„ å½•åˆ¶å¾ªç¯å¼€å§‹")
        last_check_time = time.time()
        audio_check_completed = False
        audio_started = False
        loop_count = 0
        
        while self.is_running:
            loop_count += 1
            current_time = time.time()
            
            # æ¯10ç§’è¾“å‡ºä¸€æ¬¡çŠ¶æ€ä¿¡æ¯
            if loop_count % 100 == 0:
                logger.info(f"ğŸ”„ å½•åˆ¶å¾ªç¯è¿è¡Œä¸­... çŠ¶æ€: {self.recording_state}")
            
            # æ£€æŸ¥TTSæ˜¯å¦æ­£åœ¨æ’­æ”¾ï¼Œå¦‚æœæ˜¯åˆ™æš‚åœå½•éŸ³
            if self.tts_player.is_playing_audio():
                if self.recorder.is_recording:
                    self.recorder.stop_recording()
                    self.recording_state = 'PLAYING_RESPONSE'
                    logger.info("ğŸ”‡ TTSæ’­æ”¾ä¸­ï¼Œæš‚åœå½•éŸ³")
                time.sleep(0.1)
                continue
            
            # æ£€æŸ¥å¤„ç†å†·å´æ—¶é—´
            if self.recording_state == 'PROCESSING':
                if current_time - self.last_processing_time < self.processing_cooldown:
                    time.sleep(0.1)
                    continue
                else:
                    self.recording_state = 'WAITING_FOR_WAKE_WORD'
                    logger.info("ğŸ”„ å†·å´æ—¶é—´ç»“æŸï¼Œç­‰å¾…å”¤é†’è¯")
                    print("ğŸ¤ ç­‰å¾…å”¤é†’è¯ 'å¤¸çˆ¶'...")
            
            if self.recorder.is_recording:
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢å½•åˆ¶
                if self.recorder.should_stop_recording():
                    print("ğŸ›‘ æ£€æµ‹åˆ°è¯­éŸ³è¾“å…¥ï¼Œæ­£åœ¨å¤„ç†...")
                    logger.info("ğŸ›‘ æ£€æµ‹åˆ°åº”è¯¥åœæ­¢å½•åˆ¶")
                    audio_data = self.recorder.stop_recording()
                    
                    if audio_data is not None:
                        logger.info(f"ğŸµ è·å¾—éŸ³é¢‘æ•°æ®ï¼Œé•¿åº¦: {len(audio_data)}")
                        # å¤„ç†éŸ³é¢‘
                        self._process_audio_with_wake_word_detection(audio_data)
                    else:
                        logger.info("ğŸ”‡ æ²¡æœ‰è·å¾—éŸ³é¢‘æ•°æ®ï¼Œå¤„ç†ç©ºéŸ³é¢‘")
                        # å¤„ç†ç©ºéŸ³é¢‘
                        self._process_empty_audio()
                    # é‡ç½®å¯åŠ¨æ ‡å¿—
                    audio_started = False
            else:
                # æ ¹æ®çŠ¶æ€å†³å®šæ˜¯å¦å¼€å§‹å½•éŸ³
                if self.recording_state in ['IDLE', 'WAITING_FOR_WAKE_WORD']:
                    # åªåœ¨å¯åŠ¨æ—¶æ£€æŸ¥ä¸€æ¬¡éŸ³é¢‘è®¾å¤‡çŠ¶æ€
                    if not audio_check_completed:
                        print("ğŸ” æ£€æŸ¥éŸ³é¢‘è®¾å¤‡...")
                        logger.info("ğŸ” æ£€æŸ¥éŸ³é¢‘è®¾å¤‡...")
                        try:
                            # è·å–éŸ³é¢‘è®¾å¤‡åˆ—è¡¨
                            devices = sd.query_devices()
                            logger.info(f"ğŸµ éŸ³é¢‘è®¾å¤‡åˆ—è¡¨: {len(devices)} ä¸ªè®¾å¤‡")
                            input_devices = [i for i, dev in enumerate(devices) if dev['max_input_channels'] > 0]
                            logger.info(f"ğŸ¤ è¾“å…¥è®¾å¤‡: {input_devices}")
                            
                            if input_devices:
                                print("ğŸµ æ‰¾åˆ°è¾“å…¥è®¾å¤‡ï¼Œç­‰å¾…è¯­éŸ³è¾“å…¥...")
                                logger.info("ğŸµ æ‰¾åˆ°è¾“å…¥è®¾å¤‡ï¼Œå¼€å§‹å½•åˆ¶...")
                                # é™é»˜å¯åŠ¨å½•åˆ¶ï¼Œä¸æ‰“å°ä¿¡æ¯
                                self.recorder.start_recording()
                                audio_started = True
                                self.recording_state = 'WAITING_FOR_WAKE_WORD'
                                print("ğŸ¤ ç­‰å¾…å”¤é†’è¯ 'å¤¸çˆ¶'...")
                                logger.info("ğŸ¤ å¼€å§‹ç›‘å¬å”¤é†’è¯...")
                                # è®¾ç½®æ ‡å¿—ï¼Œé¿å…é‡å¤æ£€æŸ¥
                                audio_check_completed = True
                            else:
                                print("ğŸ”‡ æ²¡æœ‰æ‰¾åˆ°è¾“å…¥è®¾å¤‡ï¼Œå¤„ç†ç©ºéŸ³é¢‘...")
                                logger.info("ğŸ”‡ æ²¡æœ‰æ‰¾åˆ°è¾“å…¥è®¾å¤‡ï¼Œå¤„ç†ç©ºéŸ³é¢‘...")
                                # æ²¡æœ‰è¾“å…¥è®¾å¤‡ï¼Œç›´æ¥å¤„ç†ç©ºéŸ³é¢‘
                                self._process_empty_audio()
                                # è®¾ç½®æ ‡å¿—ï¼Œé¿å…é‡å¤æ£€æŸ¥
                                audio_check_completed = True
                        except Exception as e:
                            print(f"âŒ éŸ³é¢‘è®¾å¤‡æ£€æŸ¥å¤±è´¥: {str(e)}")
                            logger.error(f"âŒ éŸ³é¢‘è®¾å¤‡æ£€æŸ¥å¤±è´¥: {str(e)}")
                            # æ£€æŸ¥å¤±è´¥ï¼Œç›´æ¥å¤„ç†ç©ºéŸ³é¢‘
                            self._process_empty_audio()
                            audio_check_completed = True
                    else:
                        # éŸ³é¢‘è®¾å¤‡æ£€æŸ¥å·²å®Œæˆï¼Œæ­£å¸¸ç›‘å¬æ¨¡å¼
                        if not self.recorder.is_recording and not audio_started:
                            # å¦‚æœå½•åˆ¶åœæ­¢äº†ï¼Œé‡æ–°å¼€å§‹
                            logger.info("ğŸ”„ é‡æ–°å¼€å§‹å½•åˆ¶...")
                            try:
                                self.recorder.start_recording()
                                audio_started = True
                                self.recording_state = 'WAITING_FOR_WAKE_WORD'
                            except Exception as e:
                                logger.error(f"é‡æ–°å¼€å§‹å½•åˆ¶å¤±è´¥: {e}")
                                time.sleep(1.0)
                        time.sleep(0.1)
                else:
                    # å…¶ä»–çŠ¶æ€ä¸‹ç­‰å¾…ä¸€æ®µæ—¶é—´å†æ£€æŸ¥
                    time.sleep(0.1)
        
        logger.info("ğŸ›‘ å½•åˆ¶å¾ªç¯ç»“æŸ")
    
    def _process_audio(self, audio_data: np.ndarray):
        """å¤„ç†éŸ³é¢‘"""
        try:
            # 1. è¯­éŸ³è¯†åˆ«
            recognition_result = self.speech_recognizer.recognize_audio(audio_data)
            if not recognition_result:
                logger.error("è¯­éŸ³è¯†åˆ«å¤±è´¥")
                return
            
            # å‘å¸ƒè¯­éŸ³è¯†åˆ«ç»“æœ
            self.publisher.publish_recognition(recognition_result.text, recognition_result.confidence)
            
            # 2. LLMå¤„ç†
            llm_result = asyncio.run(self.llm_processor.process_text_async(recognition_result.text))
            
            # å‘å¸ƒæ„å›¾è¯†åˆ«ç»“æœ
            self.publisher.publish_command(llm_result.intent, llm_result.confidence, llm_result.action)
            
            # 3. ç”ŸæˆJSONå“åº”
            json_response = llm_result.action.get('json_response', {})
            json_response['recognition'] = {
                'text': recognition_result.text,
                'confidence': recognition_result.confidence,
                'duration': recognition_result.duration,
                'engine': recognition_result.engine
            }
            
            # åªä¿å­˜ä¸€ä¸ªæœ€æ–°çš„JSONæ–‡ä»¶
            json_path = os.path.join(os.path.dirname(__file__), "latest_response.json")
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(json_response, f, ensure_ascii=False, indent=2)
            
            logger.info(f"JSONå“åº”å·²ä¿å­˜: {json_path}")
            
            # 4. ç”ŸæˆTTSå“åº”
            # åªè¦actionä¸­æœ‰textå­—æ®µï¼Œå°±æ’­æ”¾TTS
            if 'text' in llm_result.action and llm_result.action['text']:
                tts_text = llm_result.action['text']
                print(f"ğŸ”Š ç³»ç»Ÿå›åº”: '{tts_text}'")
                print("ğŸµ æ­£åœ¨æ’­æ”¾è¯­éŸ³å›åº”...")
                
                # å¯åŠ¨ASRç›‘å¬ï¼ˆæ”¯æŒå”¤é†’è¯æ‰“æ–­ï¼‰
                self.tts_player.start_asr_during_tts(self.speech_recognizer, self._wake_word_detected_during_tts)
                
                try:
                    # ä½¿ç”¨æµå¼TTSæ’­æ”¾
                    self.tts_player.generate_and_play_streaming_sync(tts_text)
                    print("âœ… è¯­éŸ³å›åº”æ’­æ”¾å®Œæˆ")
                except:
                    print("ğŸ›‘ ç³»ç»Ÿå›åº”è¢«ä¸­æ–­")
                
                # åœæ­¢ASRç›‘å¬
                self.tts_player.stop_asr_during_tts()
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å¾…å¤„ç†çš„å”¤é†’è¯
                if self.pending_wake_word:
                    print(f"ğŸ¯ å¤„ç†ç³»ç»Ÿå›åº”æœŸé—´çš„å”¤é†’è¯: {self.pending_wake_word}")
                    self._process_pending_wake_word()
            
            logger.info(f"å¤„ç†å®Œæˆ: {llm_result.intent} (ç½®ä¿¡åº¦: {llm_result.confidence:.2f})")
            
        except Exception as e:
            logger.error(f"éŸ³é¢‘å¤„ç†å¤±è´¥: {str(e)}")
    
    def _process_audio_with_wake_word_detection(self, audio_data: np.ndarray):
        """å¤„ç†éŸ³é¢‘å¹¶å¸¦å”¤é†’è¯æ£€æµ‹"""
        try:
            # ç«¯åˆ°ç«¯æ—¶é—´æµ‹é‡å¼€å§‹
            pipeline_start_time = time.time()
            print(f"â±ï¸ [æ€§èƒ½] å¼€å§‹å¤„ç†éŸ³é¢‘æµç¨‹ï¼ŒéŸ³é¢‘é•¿åº¦: {len(audio_data)} é‡‡æ ·ç‚¹")
            
            # 1. è¯­éŸ³è¯†åˆ«
            asr_start_time = time.time()
            print("ğŸµ æ­£åœ¨è¿›è¡Œè¯­éŸ³è¯†åˆ«...")
            recognition_result = self.speech_recognizer.recognize_audio(audio_data)
            asr_time = time.time() - asr_start_time
            print(f"â±ï¸ [æ€§èƒ½] è¯­éŸ³è¯†åˆ«è€—æ—¶: {asr_time:.3f}ç§’")
            if not recognition_result:
                print("âŒ è¯­éŸ³è¯†åˆ«å¤±è´¥")
                logger.error("è¯­éŸ³è¯†åˆ«å¤±è´¥")
                return
            
            # å‘å¸ƒè¯­éŸ³è¯†åˆ«ç»“æœ
            self.publisher.publish_recognition(recognition_result.text, recognition_result.confidence)
            
            # 2. å”¤é†’è¯æ£€æµ‹
            recognized_text = recognition_result.text.lower().strip()
            
            # æ˜¾ç¤ºASRç»“æœ
            print(f"ğŸ¤ ASRè¯†åˆ«ç»“æœ: '{recognition_result.text}'")
            
            # æ¸…ç†è¯†åˆ«æ–‡æœ¬ï¼Œç§»é™¤æ ‡ç‚¹ç¬¦å·
            cleaned_text = recognized_text.replace("ï¼Œ", ",").replace("ã€‚", ".").replace("ï¼Ÿ", "?")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å”¤é†’è¯ "å¤¸çˆ¶"
            if "å¤¸çˆ¶" in cleaned_text:
                print(f"ğŸ¯ æ£€æµ‹åˆ°å”¤é†’è¯ 'å¤¸çˆ¶'")
                logger.info(f"ğŸ¯ æ£€æµ‹åˆ°å”¤é†’è¯ 'å¤¸çˆ¶': {recognized_text}")
                self.wake_word_detected = True
                self.recording_state = 'LISTENING_FOR_COMMAND'
                
                # å¦‚æœåªæœ‰å”¤é†’è¯æ²¡æœ‰å…¶ä»–å†…å®¹ï¼Œæç¤ºç”¨æˆ·
                command_text = cleaned_text.replace("å¤¸çˆ¶", "").strip()
                # ç§»é™¤æ ‡ç‚¹ç¬¦å·åæ£€æŸ¥æ˜¯å¦ä¸ºç©º
                command_text = command_text.replace(",", "").replace(".", "").replace("?", "").strip()
                if len(command_text) == 0:
                    print("ğŸ¤ åªæ£€æµ‹åˆ°å”¤é†’è¯ï¼Œç­‰å¾…æŒ‡ä»¤...")
                    logger.info("ğŸ¤ åªæ£€æµ‹åˆ°å”¤é†’è¯ï¼Œç­‰å¾…æŒ‡ä»¤...")
                    # å¤„ç†åªæœ‰å”¤é†’è¯çš„æƒ…å†µ
                    llm_result = asyncio.run(self.llm_processor.process_text_async("wake_word_only"))
                    # åªè¦actionä¸­æœ‰textå­—æ®µï¼Œå°±æ’­æ”¾TTS
                    if 'text' in llm_result.action and llm_result.action['text']:
                        print(f"ğŸ”Š TTSå›åº”: '{llm_result.action['text']}'")
                        self.recording_state = 'PLAYING_RESPONSE'
                        self.last_processing_time = time.time()
                        self.tts_player.generate_and_play_streaming_sync(llm_result.action['text'])
                        print("âœ… è¯­éŸ³å›åº”æ’­æ”¾å®Œæˆ")
                    # é‡ç½®çŠ¶æ€ï¼Œç­‰å¾…æ–°çš„æŒ‡ä»¤
                    self.wake_word_detected = False
                    self.recording_state = 'PROCESSING'
                    self.last_processing_time = time.time()
                    return
            
            # 3. æ ¹æ®çŠ¶æ€å†³å®šæ˜¯å¦å¤„ç†æŒ‡ä»¤
            if self.recording_state == 'LISTENING_FOR_COMMAND' and self.wake_word_detected:
                # ç§»é™¤å”¤é†’è¯ï¼Œåªå¤„ç†æŒ‡ä»¤éƒ¨åˆ†
                command_text = cleaned_text.replace("å¤¸çˆ¶", "").strip()
                
                if command_text:
                    print(f"ğŸ¤ å¤„ç†æŒ‡ä»¤: '{command_text}'")
                    logger.info(f"ğŸ¤ å¤„ç†æŒ‡ä»¤: {command_text}")
                    
                    # LLMå¤„ç†
                    llm_start_time = time.time()
                    print("ğŸ§  æ­£åœ¨è¿›è¡ŒLLMåˆ†æ...")
                    llm_result = asyncio.run(self.llm_processor.process_text_async(command_text))
                    llm_time = time.time() - llm_start_time
                    print(f"â±ï¸ [æ€§èƒ½] LLMå¤„ç†è€—æ—¶: {llm_time:.3f}ç§’")
                    
                    # å‘å¸ƒæ„å›¾è¯†åˆ«ç»“æœ
                    self.publisher.publish_command(llm_result.intent, llm_result.confidence, llm_result.action)
                    
                    # ç”ŸæˆJSONå“åº”
                    json_response = llm_result.action.get('json_response', {})
                    json_response['recognition'] = {
                        'text': recognition_result.text,
                        'confidence': recognition_result.confidence,
                        'duration': recognition_result.duration,
                        'engine': recognition_result.engine,
                        'wake_word_detected': True,
                        'command_text': command_text
                    }
                    
                    # åªä¿å­˜ä¸€ä¸ªæœ€æ–°çš„JSONæ–‡ä»¶
                    json_path = os.path.join(os.path.dirname(__file__), "latest_response.json")
                    with open(json_path, 'w', encoding='utf-8') as f:
                        json.dump(json_response, f, ensure_ascii=False, indent=2)
                    
                    logger.info(f"JSONå“åº”å·²ä¿å­˜: {json_path}")
                    
                    # ç”ŸæˆTTSå“åº”
                    # åªè¦actionä¸­æœ‰textå­—æ®µï¼Œå°±æ’­æ”¾TTS
                    if 'text' in llm_result.action and llm_result.action['text']:
                        tts_text = llm_result.action['text']
                        print(f"ğŸ”Š TTSå›åº”: '{tts_text}'")
                        print("ğŸµ æ­£åœ¨æ’­æ”¾è¯­éŸ³å›åº”...")
                        self.recording_state = 'PLAYING_RESPONSE'
                        self.last_processing_time = time.time()
                        
                        # å¯åŠ¨ASRç›‘å¬ï¼ˆåœ¨TTSæ’­æ”¾æœŸé—´ç›‘å¬å”¤é†’è¯ï¼‰
                        self.tts_player.start_asr_during_tts(self.speech_recognizer, self._wake_word_detected_during_tts)
                        
                        # å“åº”å¼€å§‹æ—¶é—´ï¼ˆåœ¨TTSå¼€å§‹ç”Ÿæˆå‰æµ‹é‡ï¼‰
                        response_start_time = time.time() - pipeline_start_time
                        print(f"â±ï¸ [æ€§èƒ½] å“åº”å¼€å§‹æ—¶é—´: {response_start_time:.3f}ç§’")
                        print(f"â±ï¸ [æ€§èƒ½] å¤„ç†æ—¶é—´åˆ†å¸ƒ - ASR: {asr_time:.3f}s, LLM: {llm_time:.3f}s")
                        
                        # æ›´æ–°æ€§èƒ½ç»Ÿè®¡ï¼ˆå“åº”å¼€å§‹æ—¶é—´ï¼‰
                        self._update_performance_stats(asr_time, llm_time, 0.0, response_start_time)
                        
                        try:
                            # ä½¿ç”¨æµå¼TTSæ’­æ”¾
                            print("ğŸµ æ­£åœ¨ç”ŸæˆTTS...")
                            
                            # åˆ†ç¦»TTSç”Ÿæˆå’Œæ’­æ”¾æ—¶é—´
                            tts_generation_time = self.tts_player.generate_and_play_streaming_sync(tts_text)
                            
                            print(f"âœ… è¯­éŸ³å›åº”æ’­æ”¾å®Œæˆ")
                            print(f"â±ï¸ [æ€§èƒ½] TTSç”Ÿæˆè€—æ—¶: {tts_generation_time:.3f}ç§’")
                            
                        except:
                            print("ğŸ›‘ TTSæ’­æ”¾è¢«ä¸­æ–­")
                        
                        # åœæ­¢ASRç›‘å¬
                        self.tts_player.stop_asr_during_tts()
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰å¾…å¤„ç†çš„å”¤é†’è¯
                        if self.pending_wake_word:
                            print(f"ğŸ¯ å¤„ç†TTSæœŸé—´æ£€æµ‹åˆ°çš„å”¤é†’è¯: {self.pending_wake_word}")
                            self._process_pending_wake_word()
                        else:
                            # æ­£å¸¸ç»“æŸï¼Œé‡ç½®çŠ¶æ€
                            self.recording_state = 'PROCESSING'
                            self.last_processing_time = time.time()
                    
                    print(f"âœ… æŒ‡ä»¤å¤„ç†å®Œæˆ: {llm_result.intent} (ç½®ä¿¡åº¦: {llm_result.confidence:.2f})")
                    logger.info(f"æŒ‡ä»¤å¤„ç†å®Œæˆ: {llm_result.intent} (ç½®ä¿¡åº¦: {llm_result.confidence:.2f})")
                    
                    # é‡ç½®å”¤é†’è¯çŠ¶æ€ï¼Œè¿›å…¥å†·å´æ—¶é—´
                    self.wake_word_detected = False
                    self.recording_state = 'PROCESSING'
                    self.last_processing_time = time.time()
                else:
                    print("ğŸ¤ æ£€æµ‹åˆ°å”¤é†’è¯ä½†æ²¡æœ‰æœ‰æ•ˆæŒ‡ä»¤")
                    logger.info("ğŸ¤ æ£€æµ‹åˆ°å”¤é†’è¯ä½†æ²¡æœ‰æœ‰æ•ˆæŒ‡ä»¤")
                    self.recording_state = 'WAITING_FOR_WAKE_WORD'
            else:
                # æ²¡æœ‰æ£€æµ‹åˆ°å”¤é†’è¯ï¼Œå¿½ç•¥è¿™æ®µéŸ³é¢‘
                print(f"ğŸ”‡ æœªæ£€æµ‹åˆ°å”¤é†’è¯ï¼Œå¿½ç•¥: '{recognized_text}'")
                logger.info(f"ğŸ”‡ æœªæ£€æµ‹åˆ°å”¤é†’è¯ï¼Œå¿½ç•¥: {recognized_text}")
                self.recording_state = 'WAITING_FOR_WAKE_WORD'
            
        except Exception as e:
            print(f"âŒ éŸ³é¢‘å¤„ç†å¤±è´¥: {str(e)}")
            logger.error(f"éŸ³é¢‘å¤„ç†å¤±è´¥: {str(e)}")
            self.recording_state = 'WAITING_FOR_WAKE_WORD'
    
    def _process_pending_wake_word(self):
        """å¤„ç†TTSæœŸé—´æ£€æµ‹åˆ°çš„å”¤é†’è¯"""
        if not self.pending_wake_word:
            return
        
        try:
            print(f"ğŸ¯ å¤„ç†å¾…å¤„ç†çš„å”¤é†’è¯: {self.pending_wake_word}")
            
            # è·å–å‘½ä»¤æ–‡æœ¬
            command_text = self.pending_command
            
            # é‡ç½®å¾…å¤„ç†çŠ¶æ€
            self.pending_wake_word = None
            self.pending_command = None
            
            # è®¾ç½®çŠ¶æ€ä¸ºå¤„ç†ä¸­
            self.recording_state = 'PROCESSING'
            self.last_processing_time = time.time()
            
            if command_text == "wake_word_only":
                # åªæœ‰å”¤é†’è¯ï¼Œæ²¡æœ‰å‘½ä»¤
                print("ğŸ¤ åªæ£€æµ‹åˆ°å”¤é†’è¯ï¼Œç”Ÿæˆå›åº”...")
                llm_result = asyncio.run(self.llm_processor.process_text_async("wake_word_only"))
                
                if 'text' in llm_result.action and llm_result.action['text']:
                    print(f"ğŸ”Š å”¤é†’è¯å›åº”: '{llm_result.action['text']}'")
                    
                    # å¯åŠ¨ASRç›‘å¬ï¼ˆæ”¯æŒå”¤é†’è¯æ‰“æ–­ï¼‰
                    self.tts_player.start_asr_during_tts(self.speech_recognizer, self._wake_word_detected_during_tts)
                    
                    try:
                        self.tts_player.generate_and_play_streaming_sync(llm_result.action['text'])
                        print("âœ… å”¤é†’è¯å›åº”æ’­æ”¾å®Œæˆ")
                    except:
                        print("ğŸ›‘ å”¤é†’è¯å›åº”è¢«ä¸­æ–­")
                    
                    # åœæ­¢ASRç›‘å¬
                    self.tts_player.stop_asr_during_tts()
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰å¾…å¤„ç†çš„å”¤é†’è¯
                    if self.pending_wake_word:
                        print(f"ğŸ¯ å¤„ç†å”¤é†’è¯å›åº”æœŸé—´çš„å”¤é†’è¯: {self.pending_wake_word}")
                        self._process_pending_wake_word()
            else:
                # æœ‰å…·ä½“çš„å‘½ä»¤
                print(f"ğŸ¤ å¤„ç†TTSæœŸé—´çš„å‘½ä»¤: '{command_text}'")
                
                # LLMå¤„ç†
                llm_result = asyncio.run(self.llm_processor.process_text_async(command_text))
                
                # å‘å¸ƒæ„å›¾è¯†åˆ«ç»“æœ
                self.publisher.publish_command(llm_result.intent, llm_result.confidence, llm_result.action)
                
                # ç”ŸæˆJSONå“åº”
                json_response = llm_result.action.get('json_response', {})
                json_response['recognition'] = {
                    'text': self.pending_wake_word,
                    'confidence': 0.9,
                    'duration': 0.0,
                    'engine': 'tts_interrupt',
                    'wake_word_detected': True,
                    'command_text': command_text,
                    'interrupted': True
                }
                
                # ä¿å­˜JSONå“åº”
                json_path = os.path.join(os.path.dirname(__file__), "latest_response.json")
                with open(json_path, 'w', encoding='utf-8') as f:
                    json.dump(json_response, f, ensure_ascii=False, indent=2)
                
                logger.info(f"TTSä¸­æ–­JSONå“åº”å·²ä¿å­˜: {json_path}")
                
                # æ’­æ”¾æ–°çš„TTSå›åº”
                if 'text' in llm_result.action and llm_result.action['text']:
                    tts_text = llm_result.action['text']
                    print(f"ğŸ”Š æ–°çš„TTSå›åº”: '{tts_text}'")
                    print("ğŸµ æ­£åœ¨æ’­æ”¾æ–°çš„è¯­éŸ³å›åº”...")
                    
                    # å†æ¬¡å¯åŠ¨ASRç›‘å¬ï¼ˆæ”¯æŒåµŒå¥—ä¸­æ–­ï¼‰
                    self.tts_player.start_asr_during_tts(self.speech_recognizer, self._wake_word_detected_during_tts)
                    
                    try:
                        self.tts_player.generate_and_play_streaming_sync(tts_text)
                        print("âœ… æ–°çš„è¯­éŸ³å›åº”æ’­æ”¾å®Œæˆ")
                    except:
                        print("ğŸ›‘ æ–°çš„TTSæ’­æ”¾è¢«ä¸­æ–­")
                    
                    # åœæ­¢ASRç›‘å¬
                    self.tts_player.stop_asr_during_tts()
                    
                    # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å¾…å¤„ç†çš„å”¤é†’è¯
                    if self.pending_wake_word:
                        print(f"ğŸ¯ å¤„ç†åµŒå¥—çš„å”¤é†’è¯: {self.pending_wake_word}")
                        self._process_pending_wake_word()
                
                print(f"âœ… TTSæœŸé—´æŒ‡ä»¤å¤„ç†å®Œæˆ: {llm_result.intent} (ç½®ä¿¡åº¦: {llm_result.confidence:.2f})")
            
            # é‡ç½®çŠ¶æ€
            self.recording_state = 'WAITING_FOR_WAKE_WORD'
            
        except Exception as e:
            print(f"âŒ å¤„ç†å¾…å¤„ç†å”¤é†’è¯å¤±è´¥: {e}")
            logger.error(f"å¤„ç†å¾…å¤„ç†å”¤é†’è¯å¤±è´¥: {e}")
            self.recording_state = 'WAITING_FOR_WAKE_WORD'
    
    def _process_empty_audio(self):
        """å¤„ç†ç©ºéŸ³é¢‘ï¼ˆæ²¡æœ‰éº¦å…‹é£è¾“å…¥çš„æƒ…å†µï¼‰"""
        try:
            print("ğŸ¤ å¤„ç†ç©ºéŸ³é¢‘ï¼ˆæ²¡æœ‰éº¦å…‹é£è¾“å…¥ï¼‰")
            logger.info("ğŸ¤ å¤„ç†ç©ºéŸ³é¢‘ï¼ˆæ²¡æœ‰éº¦å…‹é£è¾“å…¥ï¼‰")
            
            # ç©ºéŸ³é¢‘ä¸åº”è¯¥è°ƒç”¨LLMæˆ–æ’­æ”¾TTSï¼Œåªæ˜¯ç®€å•è®°å½•
            print("ğŸ”‡ ç©ºéŸ³é¢‘ï¼Œè·³è¿‡LLMè°ƒç”¨å’ŒTTSæ’­æ”¾")
            logger.info("ğŸ”‡ ç©ºéŸ³é¢‘ï¼Œè·³è¿‡LLMè°ƒç”¨å’ŒTTSæ’­æ”¾")
            
            # åˆ›å»ºç©ºçš„è¯†åˆ«ç»“æœ
            recognition_result = RecognitionResult(
                text="",
                confidence=0.0,
                duration=0.0,
                engine="empty"
            )
            
            # å‘å¸ƒè¯­éŸ³è¯†åˆ«ç»“æœ
            self.publisher.publish_recognition(recognition_result.text, recognition_result.confidence)
            
            # æ˜¾ç¤ºASRç»“æœ
            print("ğŸ¤ ASRè¯†åˆ«ç»“æœ: '' (æ— è¯­éŸ³è¾“å…¥)")
            print("âœ… ç©ºéŸ³é¢‘å¤„ç†å®Œæˆï¼šæ— è¯­éŸ³è¾“å…¥ï¼Œç­‰å¾…ä¸‹ä¸€æ¬¡å½•éŸ³")
            
        except Exception as e:
            print(f"âŒ ç©ºéŸ³é¢‘å¤„ç†å¤±è´¥: {str(e)}")
            logger.error(f"ç©ºéŸ³é¢‘å¤„ç†å¤±è´¥: {str(e)}")
            import traceback
            logger.error(f"ç©ºéŸ³é¢‘å¤„ç†é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
    
    def start(self):
        """å¯åŠ¨ç³»ç»Ÿ"""
        if self.is_running:
            logger.warning("ç³»ç»Ÿå·²ç»åœ¨è¿è¡Œä¸­")
            return
        
        if self.input_mode == 'voice':
            self._start_voice_mode()
        else:
            self._start_text_mode()
    
    def _start_voice_mode(self):
        """å¯åŠ¨è¯­éŸ³æ¨¡å¼"""
        print("ğŸš€ å¯åŠ¨æ­£å¼ç‰ˆè¯­éŸ³è¯†åˆ«ç³»ç»Ÿ...")
        print("=" * 60)
        print("ğŸ¤ è¯­éŸ³è¯†åˆ«+LLM+TTSç³»ç»Ÿ")
        print("å®æ—¶è¯­éŸ³å½•åˆ¶ -> LLMåˆ†æ -> JSONç”Ÿæˆ -> TTSåé¦ˆ")
        print("æ”¯æŒå”¤é†’è¯æ£€æµ‹ã€ROSè¯é¢˜å‘å¸ƒã€å†…å­˜TTSæµå¼æ’­æ”¾")
        print("=" * 60)
        print("ğŸ’¡ ä½¿ç”¨æ–¹æ³•ï¼šè¯´'å¤¸çˆ¶'å”¤é†’ï¼Œç„¶åè¯´'æŒ¥æ‰‹'æˆ–'æŠ±æ‹³'")
        print("ğŸ’¡ æç¤ºï¼šæŒ‰Ctrl+Cå¯ä»¥åœæ­¢")
        print("ğŸ’¡ æ€§èƒ½ç›‘æ§ï¼šåœ¨å‘½ä»¤è¡Œè¾“å…¥ 'stats' æŸ¥çœ‹æ€§èƒ½ç»Ÿè®¡")
        print("=" * 60)
        
        self.is_running = True
        
        # å¯åŠ¨å½•åˆ¶çº¿ç¨‹
        print("ğŸ”„ å¯åŠ¨å½•åˆ¶çº¿ç¨‹...")
        self.recording_thread = threading.Thread(target=self._recording_loop)
        self.recording_thread.daemon = True
        self.recording_thread.start()
        print("âœ… å½•åˆ¶çº¿ç¨‹å·²å¯åŠ¨")
        
        # ç­‰å¾…ä¸€ä¸‹ç¡®ä¿å½•åˆ¶çº¿ç¨‹å¯åŠ¨
        time.sleep(1.0)
        
        # è‡ªåŠ¨å¼€å§‹å½•åˆ¶
        print("ğŸ¤ å¼€å§‹å½•åˆ¶...")
        try:
            self.recorder.start_recording()
            print("âœ… å½•åˆ¶å·²å¼€å§‹")
        except Exception as e:
            print(f"âŒ å½•åˆ¶å¯åŠ¨å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            self.stop()
            return
        
        print("âœ… è¯­éŸ³æ¨¡å¼å¯åŠ¨å®Œæˆï¼Œæ­£åœ¨ç›‘å¬...")
        
        # ä¿æŒä¸»çº¿ç¨‹è¿è¡Œ
        try:
            while self.is_running:
                time.sleep(0.1)
        except KeyboardInterrupt:
            print("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨å…³é—­ç³»ç»Ÿ...")
        finally:
            self.stop()
    
    def _start_text_mode(self):
        """å¯åŠ¨æ–‡æœ¬æ¨¡å¼"""
        print("ğŸš€ å¯åŠ¨æ­£å¼ç‰ˆæ–‡æœ¬è¾“å…¥ç³»ç»Ÿ...")
        print("=" * 60)
        print("ğŸ’¬ æ–‡æœ¬è¾“å…¥+LLM+TTSç³»ç»Ÿ")
        print("æ–‡æœ¬è¾“å…¥ -> LLMåˆ†æ -> JSONç”Ÿæˆ -> TTSåé¦ˆ")
        print("æ”¯æŒROSè¯é¢˜å‘å¸ƒã€å†…å­˜TTSæµå¼æ’­æ”¾")
        print("=" * 60)
        print("ğŸ’¡ æ”¯æŒçš„æŒ‡ä»¤ï¼š")
        print("   - æŒ¥æ‰‹ã€æ‹›æ‰‹ã€helloã€wave -> è§¦å‘æŒ¥æ‰‹åŠ¨ä½œ")
        print("   - æŠ±æ‹³ã€æ•¬ç¤¼ã€welcome -> è§¦å‘æŠ±æ‹³åŠ¨ä½œ")
        print("   - åœæ­¢ã€stop -> åœæ­¢å½“å‰åŠ¨ä½œ")
        print("   - é€€å‡ºã€exit -> é€€å‡ºç¨‹åº")
        print("=" * 60)
        
        self.is_running = True
        
        # ä¿æŒä¸»çº¿ç¨‹è¿è¡Œï¼Œç­‰å¾…ç”¨æˆ·è¾“å…¥
        try:
            while self.is_running:
                try:
                    # è·å–ç”¨æˆ·è¾“å…¥
                    user_input = input("\nğŸ’¬ è¯·è¾“å…¥æŒ‡ä»¤ï¼š").strip()
                    
                    if not user_input:
                        continue
                    
                    # æ£€æŸ¥é€€å‡ºæŒ‡ä»¤
                    if user_input.lower() in ['é€€å‡º', 'exit', 'quit', 'q']:
                        print("ğŸ‘‹ å†è§ï¼")
                        break
                    
                    print(f"ğŸ“ å¤„ç†æŒ‡ä»¤: '{user_input}'")
                    
                    # å¤„ç†æ–‡æœ¬è¾“å…¥
                    self._process_text_input(user_input)
                    
                except KeyboardInterrupt:
                    print("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨å…³é—­ç³»ç»Ÿ...")
                    break
                except EOFError:
                    print("\nğŸ‘‹ è¾“å…¥ç»“æŸï¼Œå†è§ï¼")
                    break
                except Exception as e:
                    print(f"âŒ å¤„ç†è¾“å…¥å¤±è´¥: {e}")
                    logger.error(f"å¤„ç†æ–‡æœ¬è¾“å…¥å¤±è´¥: {e}")
                    
        finally:
            self.stop()
    
    def _process_text_input(self, text: str):
        """å¤„ç†æ–‡æœ¬è¾“å…¥"""
        try:
            # ç«¯åˆ°ç«¯æ—¶é—´æµ‹é‡å¼€å§‹
            pipeline_start_time = time.time()
            print(f"â±ï¸ [æ€§èƒ½] å¼€å§‹å¤„ç†æ–‡æœ¬è¾“å…¥: '{text[:30]}...'")
            
            # å‘å¸ƒè¯­éŸ³è¯†åˆ«ç»“æœï¼ˆæ¨¡æ‹Ÿï¼‰
            self.publisher.publish_recognition(text, 1.0)
            
            # LLMå¤„ç†
            llm_start_time = time.time()
            print("ğŸ§  æ­£åœ¨åˆ†ææŒ‡ä»¤...")
            llm_result = asyncio.run(self.llm_processor.process_text_async(text))
            llm_time = time.time() - llm_start_time
            print(f"â±ï¸ [æ€§èƒ½] LLMå¤„ç†è€—æ—¶: {llm_time:.3f}ç§’")
            
            # å‘å¸ƒVLAæŒ‡ä»¤
            self.publisher.publish_command(llm_result.intent, llm_result.confidence, llm_result.action)
            
            # ç”ŸæˆJSONå“åº”
            json_response = llm_result.action.get('json_response', {})
            json_response['recognition'] = {
                'text': text,
                'confidence': 1.0,
                'duration': 0.0,
                'engine': 'text_input'
            }
            
            # ä¿å­˜JSONå“åº”
            json_path = os.path.join(os.path.dirname(__file__), "latest_response.json")
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(json_response, f, ensure_ascii=False, indent=2)
            
            logger.info(f"JSONå“åº”å·²ä¿å­˜: {json_path}")
            
            # ç”ŸæˆTTSå“åº”
            # åªè¦actionä¸­æœ‰textå­—æ®µï¼Œå°±æ’­æ”¾TTS
            if 'text' in llm_result.action and llm_result.action['text']:
                response_text = llm_result.action['text']
                print(f"ğŸ”Š ç³»ç»Ÿå›åº”: '{response_text}'")
                print("ğŸµ æ­£åœ¨æ’­æ”¾è¯­éŸ³å›åº”...")
                
                # å¯åŠ¨ASRç›‘å¬ï¼ˆæ”¯æŒå”¤é†’è¯æ‰“æ–­ï¼‰
                self.tts_player.start_asr_during_tts(self.speech_recognizer, self._wake_word_detected_during_tts)
                
                # TTSå¤„ç†
                tts_start_time = time.time()
                try:
                    # ä½¿ç”¨æµå¼TTSæ’­æ”¾
                    tts_generation_time = self.tts_player.generate_and_play_streaming_sync(response_text)
                    tts_time = tts_generation_time if tts_generation_time else 0.0
                    print("âœ… è¯­éŸ³å›åº”æ’­æ”¾å®Œæˆ")
                    print(f"â±ï¸ [æ€§èƒ½] TTSç”Ÿæˆè€—æ—¶: {tts_time:.3f}ç§’")
                except:
                    print("ğŸ›‘ ç³»ç»Ÿå›åº”è¢«ä¸­æ–­")
                    tts_time = 0.0
                
                # åœæ­¢ASRç›‘å¬
                self.tts_player.stop_asr_during_tts()
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å¾…å¤„ç†çš„å”¤é†’è¯
                if self.pending_wake_word:
                    print(f"ğŸ¯ å¤„ç†æ–‡æœ¬è¾“å…¥å›åº”æœŸé—´çš„å”¤é†’è¯: {self.pending_wake_word}")
                    self._process_pending_wake_word()
                
                # å“åº”å¼€å§‹æ—¶é—´ç»Ÿè®¡
                response_start_time = time.time() - pipeline_start_time
                print(f"â±ï¸ [æ€§èƒ½] å“åº”å¼€å§‹æ—¶é—´: {response_start_time:.3f}ç§’")
                print(f"â±ï¸ [æ€§èƒ½] å¤„ç†æ—¶é—´åˆ†å¸ƒ - LLM: {llm_time:.3f}s, TTSç”Ÿæˆ: {tts_time:.3f}s")
                
                # æ›´æ–°æ€§èƒ½ç»Ÿè®¡
                self._update_performance_stats(0.0, llm_time, tts_time, response_start_time)  # ASRæ—¶é—´ä¸º0ï¼ˆæ–‡æœ¬è¾“å…¥ï¼‰
            
            print(f"âœ… æŒ‡ä»¤å¤„ç†å®Œæˆ: {llm_result.intent} (ç½®ä¿¡åº¦: {llm_result.confidence:.2f})")
            
        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡æœ¬è¾“å…¥å¤±è´¥: {e}")
            logger.error(f"å¤„ç†æ–‡æœ¬è¾“å…¥å¤±è´¥: {e}")
            import traceback
            logger.error(f"æ–‡æœ¬è¾“å…¥é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
    
    def stop(self):
        """åœæ­¢ç³»ç»Ÿ"""
        if not self.is_running:
            return
        
        logger.info("ğŸ›‘ æ­£åœ¨åœæ­¢ç³»ç»Ÿ...")
        self.is_running = False
        
        # åœæ­¢å½•åˆ¶
        if self.recorder.is_recording:
            self.recorder.stop_recording()
        
        # ç­‰å¾…çº¿ç¨‹ç»“æŸ
        if self.recording_thread and self.recording_thread.is_alive():
            self.recording_thread.join(timeout=1.0)
        
        logger.info("âœ… ç³»ç»Ÿå·²åœæ­¢")

def load_audio_config() -> Dict[str, Any]:
    """åŠ è½½éŸ³é¢‘é…ç½®"""
    audio_config_path = os.path.join(os.path.dirname(__file__), '..', 'config', 'audio_config.yaml')
    
    if os.path.exists(audio_config_path):
        import yaml
        with open(audio_config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    # é»˜è®¤éŸ³é¢‘é…ç½®
    return {
        'audio_mode': 'microphone',
        'asr': {
            'input_device': 'hw:3,0',  # USB Composite Device: Audio
            'sample_rate': 48000,  # USBè®¾å¤‡æ”¯æŒçš„é‡‡æ ·ç‡
            'channels': 1,
            'chunk_duration': 0.05,
            'silence_threshold': 0.01,
            'silence_duration': 1.5,
            'min_recording_duration': 0.5,
            'vad_threshold': 0.005,
            'min_audio_length': 1.0
        },
        'tts': {
            'output_device': 'default',
            'voice': 'zh-CN-XiaoxiaoNeural',
            'rate': '+0%',
            'volume': '+0%'
        },
        'debug': {
            'enabled': False,
            'log_device_info': True
        }
    }

def load_config() -> Dict[str, Any]:
    """åŠ è½½é…ç½®"""
    config_path = os.path.join(os.path.dirname(__file__), '..', 'config', 'llm_params.yaml')
    
    if os.path.exists(config_path):
        import yaml
        with open(config_path, 'r', encoding='utf-8') as f:
            llm_config = yaml.safe_load(f)
    else:
        llm_config = {}
    
    # åŠ è½½éŸ³é¢‘é…ç½®
    audio_config = load_audio_config()
    
    # åˆå¹¶é…ç½®
    config = {
        'audio_mode': audio_config.get('audio_mode', 'microphone'),
        'asr': audio_config.get('asr', {}),
        'speech': {
            'model_name': 'small',
            'vad_threshold': audio_config.get('asr', {}).get('vad_threshold', 0.005),
            'min_audio_length': audio_config.get('asr', {}).get('min_audio_length', 1.0)
        },
        'llm': {
            'engine_type': 'zhipuai',
            'max_tokens': 100,
            'temperature': 0.1,
            'timeout': 5.0,
            'cache_timeout': 300
        },
        'tts': audio_config.get('tts', {}),
        'debug': audio_config.get('debug', {})
    }
    
    # æ›´æ–°LLMé…ç½®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if llm_config:
        config['llm'].update(llm_config.get('llm', {}))
    
    return config

def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='VLAè¯­è¨€ç³»ç»Ÿ - æ”¯æŒè¯­éŸ³å’Œæ–‡æœ¬è¾“å…¥')
    parser.add_argument('--input_mode', choices=['voice', 'text'], default='voice',
                       help='è¾“å…¥æ¨¡å¼ (voice=è¯­éŸ³è¯†åˆ«, text=æ–‡æœ¬è¾“å…¥)')
    parser.add_argument('--config', help='é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰')
    
    args = parser.parse_args()
    
    print("ğŸš€ å¼€å§‹å¯åŠ¨VLAè¯­è¨€ç³»ç»Ÿ...")
    print(f"ğŸ“ è¾“å…¥æ¨¡å¼: {args.input_mode}")
    
    try:
        # åŠ è½½é…ç½®
        print("ğŸ“‹ æ­£åœ¨åŠ è½½é…ç½®...")
        config = load_config()
        print("âœ… é…ç½®åŠ è½½å®Œæˆ")
        
        # åˆå§‹åŒ–ç³»ç»Ÿ
        print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–ç³»ç»Ÿ...")
        system = ProductionSystem(config, args.input_mode)
        print("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        
        # å¯åŠ¨ç³»ç»Ÿ
        print("ğŸš€ æ­£åœ¨å¯åŠ¨ç³»ç»Ÿ...")
        system.start()
        
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿå¯åŠ¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == '__main__':
    main()
